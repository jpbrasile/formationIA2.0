# FormationIA2.0

<details>
<summary><b>Qu'est-ce que l'IA peut vous rapporter ?</b></summary>
<p>Ce document est int√©ressant car il explore l'impact r√©el des Mod√®les de Langage √† Grande √âchelle (LLM), comme GPT-4, sur des t√¢ches complexes et riches en connaissances. L'√©tude, men√©e avec le Boston Consulting Group, impliquait 758 consultants et visait √† comprendre comment l'IA peut am√©liorer la performance humaine dans un contexte professionnel.</p>
<p>Principales conclusions de l'√©tude :</p>
<ul>
    <li><strong>Productivit√© et Qualit√© Accrues</strong> : Les consultants utilisant l'IA √©taient nettement plus productifs et produisaient un travail de meilleure qualit√©. En moyenne, ils ont compl√©t√© 12,2 % de t√¢ches en plus et ce, 25,1 % plus rapidement. De plus, la qualit√© de leur travail √©tait sup√©rieure de plus de 40 % par rapport √† ceux n'utilisant pas l'IA.</li>
    <li><strong>B√©n√©fices √† Tous les Niveaux de Comp√©tences</strong> : L'√©tude a r√©v√©l√© que l'augmentation par l'IA profitait significativement aux consultants √† tous les niveaux de comp√©tence. Ceux en dessous du seuil de performance moyen ont vu leur performance augmenter de 43 %, tandis que ceux au-dessus ont am√©lior√© de 17 %.</li>
    <li><strong>Limites de l'IA</strong> : L'√©tude a √©galement identifi√© des t√¢ches actuellement hors de port√©e de l'IA. Pour ces t√¢ches, les consultants utilisant l'IA √©taient 19 points de pourcentage moins susceptibles de produire des solutions correctes par rapport √† ceux sans acc√®s √† l'IA.</li>
    <li><strong>Mod√®les d'Int√©gration de l'IA</strong> : L'√©tude a observ√© deux mod√®les distincts dans la fa√ßon dont les consultants int√©graient l'IA dans leur travail :
        <ul>
            <li><strong>Centaures</strong> : Certains consultants agissaient comme des Centaures, divisant les t√¢ches entre eux et l'IA, d√©l√©guant certaines activit√©s √† l'IA.</li>
            <li><strong>Cyborgs</strong> : D'autres agissaient plus comme des Cyborgs, int√©grant compl√®tement leur flux de travail avec l'IA et interagissant continuellement avec elle.</li>
        </ul>
    </li>
</ul>
<p>Pour plus de d√©tails, consultez le document complet : <a href="https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf">Lien vers l'√©tude</a>.</p>
</details>


<details>
  <summary> <b>Les astuces √† utiliser</b></summary>
  <br> 
  <details>
    <summary> Impression d'√©cran sous windows?</summary>
   
    Touche Windows+MAj+S
  </details>
  <details>
    <summary> Ins√©rer l'image dans GitHub</summary>

    T√©l√©charger l'image puis simple upload au point de la page wiki o√π l'on veut mettre l'image
  </details>
  <details>
    <summary> Pour obtenir de chatGPT un format markdown √† couper/coller </summary>
  
    "Fournis le contenu format√© en Markdown, pr√©sent√© sous forme de cha√Æne de caract√®res " 
  </details>


   <details>
    <summary>acc√©der √† toutes les commandes d'Harpa </summary>

   il suffit de mettre "/" dans le chat; ex: "/clear": supprime l'historique des chats.
  </details>
</details>
  
</details>


## Formation √† l'IA en 2024: 

Dans le tableau ci-apr√®s: 3 niveaux de formation : D√©butant, interm√©diaire et avanc√©
- **Quels outils ?** : Ceux √† ma√Ætriser pour √™tre efficace:  Halte aux probl√®mes ! Euh non !  "**Alt A <Probl√®me>!**" et Harpa.ai vous r√©pondra !
- **Le prompt** : Comment parler avec le chatbot pour que sa r√©ponse soit pertinente ?
- **Fournir aux LLM nos propres donn√©es** : Comment le chatbot peut prendre en compte mes donn√©es ?
- **Acc√®s √† Internet**: Comment faire pour qu'il prenne les donn√©es pertinantes sur le cloud ?
- **G√©rer le Contexte**: Comment composer avec sa m√©moire vive qui ne peut accumuler qu'un nombre fini de donn√©es ?
- **Au del√† de l'√©crit** : Comment travailler avec des donn√©es non textuelles (images, son ... ) tant en entr√©e qu'en sortie ?
- **L'acc√®s aux outils externes**: Comment faire que le chatbot acc√®de √† des ressources externes disponibles sur le web ?
- **Chatbots sp√©cialis√©s** : Comment cr√©er des chatbots sp√©cialis√©s pour remplir certaines t√¢ches ?
- **Travail en √©quipe**: Comment cr√©er des chatbots travaillant en √©quipe
- **L'IA apprend toute seule** : Comment faire pour que les Chatbot apprennent de leurs erreurs ?

| Niveau        | Objectif                              | [Quels outils  ?](https://github.com/jpbrasile/formationIA2.0/wiki/Installation-des-outils.md)                           | [Le prompt](https://github.com/jpbrasile/formationIA2.0/wiki/4.-Le-prompting)                                           | [Fournir aux LLM nos propres donn√©es](https://github.com/jpbrasile/formationIA2.0/wiki/6.-Fournir-aux-LLM-nos-propres-donn%C3%A9es)                                               | [L'Acc√®s √† Internet](https://github.com/jpbrasile/formationIA2.0/wiki/L'acc%C3%A8s-%C3%A0-internet.md)                                            | [G√©rer le contexte](https://github.com/jpbrasile/formationIA2.0/wiki/5.-Gestion-du-contexte)                                             | [Au del√† de l'√©crit](https://github.com/jpbrasile/formationIA2.0/wiki/9.-Les-LLM-multimodaux-(MLLM))                                         | [L'acc√®s aux outils externes](https://github.com/jpbrasile/formationIA2.0/wiki/8.-L%E2%80%99Acc%C3%A8s-aux-API)                                               | [Chatbots sp√©cialis√©s](https://github.com/jpbrasile/formationIA2.0/wiki/A.-Les-GPTs)                                              | [Travail en √©quipe](https://github.com/jpbrasile/formationIA2.0/wiki/B.-Les-agents)                                           | [L'IA apprend toute seule](https://github.com/jpbrasile/formationIA2.0/wiki/C.-L%E2%80%99apprentissage-par-renforcement-:)                                               |
|---------------|---------------------------------------|-----------------------------------------|------------------------------------------------------|------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------|---------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| D√©butant      | [Utiliser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/1-%20prendre%20des%20notes.md) [challenge](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/challenge.md)       | [Nos outils:](https://github.com/jpbrasile/formationIA2.0/wiki/01:-Comment-disposer-d'outils-qui-font-tout-pour-vous-%3F)  [ChatGPT](https://chat.openai.com/), [Copilot](https://copilot.microsoft.com/?culture=fr-fr&country=fr), [Harpa](https://harpa.ai/), [Perplexity](https://www.perplexity.ai/), [Canva](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/canva.md)           [ GitHub, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/github.md) [Capcut](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/capcut.md)  | [Les bases](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/3-%20le%20prompting.md) |Avec nos outils       | Avec nos outils              |  Un prompt pour demander la synth√®se   | Copilot (dessin) et [outils en ligne, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/multimodal.md)| [Runway](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/Runway.md) [Outils en ligne](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/5-%20API.md)          |  |                |
| Interm√©diaire | [Ma√Ætriser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)  [DeepLearning courses](https://www.deeplearning.ai/short-courses/)        | [Quel LLM ? ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhatLLM.md) [MixtralReplicate, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Replicate.md)    (MistralM√©dium](https://jeanviet.fr/mistral-medium/)        | [MetricMule et Formation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/le%20prompting.md)    |[Pinecone,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/RAG.md) [voiceflow,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)[Haystack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md) | [GPT Crawler,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/scraping.md) [GPT-Researcher, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPt-Researcher.md) [OnLine Shop](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/OnLineShop.md)                   | [MEMGPT,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/context.md)             | [ComfyUI,LLAVA,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/multimodal.md) [firellava](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/firellava.md) [Local ChatGPT, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Local%20ChatGPT.md) [WhisperSpeech, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhisperSpeech.md) [fuyu](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/fuyu.md)| [Langchain,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/API.md) , [Colab, HF...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)   ,[open interpreter](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Open%20Interpreter.md) [Phind, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Phind.md) [wolfram, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/programWithWolfram.md) [taskweaver, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/taskweaver.md) [AIDER, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/AIDER.md) [CURSOR](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/CURSOR.md)    | [emploi des GPTs openAI,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPTs.md) [voiceflow](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)       |     [AutoGen, CrewAI, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Agent.md) [n8n](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/n8n.md)       |   |
| Avanc√©        | [Cr√©er avec l'IA](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/challenges.md),[aller plus loin](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Apprendre%20l'IA%20en%202024.md)       |[+vite](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Etat%20de%20l'art.md),[>GPT4](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Quel%20LLM.md) [Finetuning,Quantification...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/les%20outils.md) Cr√©ation de MOE | [Prompt optimis√© par programmation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/prompting.md)                   | Cr√©ation de base de donn√©es locales       | AgentSearch et Wiki search | Gestion avanc√©e du contexte (compactage)                        | [animation 3D, audiobook...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/multimodal.md) | Conception d'API robustes pour des applications √† grande √©chelle | [Screen2Code, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/GPTs.md) [Crack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Crack.md)    | D√©veloppement d'agents autonomes capables d'apprentissage continu | Strat√©gies pour le d√©veloppement de talents en IA et gestion des changements technologiques |

## ChatGPT C'est quoi ? : 
- [00:00](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=0s) ü§ñ Qu'est-ce que ChatGPT ? [Large Language Model Base: un LLM √† la maternelle](https://github.com/jpbrasile/formationIA2.0/wiki/1.-LLM%E2%80%90Base) 

  - ChatGPT est une machine √† approximer qui fournit des r√©ponses bas√©es sur ce qu'il a appris.
  - Il est efficace pour interpoler mais peut fournir de fausses r√©ponses en l'absence de donn√©es suffisantes.
  - L'apprentissage de ChatGPT n√©cessite l'ajustement de ses param√®tres en fonction des donn√©es d'entr√©e, et il a utilis√© des milliards de donn√©es pour ajuster ses param√®tres.

- [01:11](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=71s) üìö Comment instruire ChatGPT ? : [Le LLM √† l'√©cole](https://github.com/jpbrasile/formationIA2.0/wiki/2.-LLM%E2%80%90Instruct) 
  - Pour instruire ChatGPT, il faut lui donner des directives sur son comportement.
  - Alimenter la machine avec une nouvelle base de donn√©es de type question-r√©ponse lui permet de mimer ce type de r√©sultat.
  - Des gardes-fous sont n√©cessaires pour censurer certaines r√©ponses et inculquer les bonnes mani√®res.

- [02:09](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=129s) üíª Implantation de ChatGPT

  - ChatGPT est principalement disponible en ligne via le Cloud, en raison de son co√ªt de d√©veloppement.
  - Le contr√¥le sur l'utilisation de ChatGPT est difficile, ce qui soul√®ve des pr√©occupations concernant la divulgation d'informations sensibles.
  - Un mouvement open source travaille sur des versions plus l√©g√®res de ChatGPT pour des utilisations locales.

- [03:18](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=198s) üß† La taille et le contexte des LLM : [Le LLM peut soutenir une conversation](https://github.com/jpbrasile/formationIA2.0/wiki/3.-LLM%E2%80%90Chat) 

  - Les LLM (Large Language Models) sont en constante √©volution pour devenir plus l√©gers tout en maintenant leur performance.
  - La taille des LLM est mesur√©e en milliards de bytes, et des versions plus compactes sont d√©velopp√©es.
  - Le contexte, ou m√©moire √† court terme, est crucial pour stocker des informations pertinentes lors de l'interaction avec un LLM.
 
  ## L'open-source proche de GPT4
  ![Capture d'√©cran 2024-01-24 155607](https://github.com/jpbrasile/formationIA2.0/assets/8331027/0ef1137e-e79c-405d-8816-cad6a82e41b6)

  ## Un stack local ou d√©ployable sur hostinger domaine: atthesametime.eu
  -  fait √† partir de [Colin](https://github.com/coleam00/local-ai-packaged)
  -  url:
      - n8N:    http://localhost:5678/
      - flowise: http://localhost:3001/
      - Searxng: http://localhost:8080/
      - openrouter: https://openrouter.ai/
      - openwebui: http://localhost:3000/
      - qdrant: http://localhost:6333/
      - caddy avec
          -  N8N_HOSTNAME=${N8N_HOSTNAME:-":8001"}
          - WEBUI_HOSTNAME=${WEBUI_HOSTNAME:-":8002"}
          - FLOWISE_HOSTNAME=${FLOWISE_HOSTNAME:-":8003"}
          - OLLAMA_HOSTNAME=${OLLAMA_HOSTNAME:-":8004"}
          - SUPABASE_HOSTNAME=${SUPABASE_HOSTNAME:-":8005"}
          - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-":8006"}
          - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL:-internal}
        - ollama: http://localhost:11434
- hostinger : systeme d'exploitation avec docker (application)
    - J'ai rajout√© en local:
  ```
    environment:
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true 
  ```
  dans docker-compose.yml pour n8n et n8n-import

  !!! : un point important pour le d√©ploiement :il y a des incompatibilit√© de parefeu entre docker et ufw, donc faire
  ```
  # Allow traffic within Docker's internal network
sudo ufw allow in on docker0
sudo ufw allow out on docker0
```

Issue :Issue: LocalAI stack failing to start properly due to DNS resolution problems in Docker containers.

Findings:

Docker containers couldn't resolve domain names (DNS timeout)
Host system uses systemd-resolved (127.0.0.53) which containers can't access
Hostinger VPS with DNS servers: 89.116.146.10, 1.1.1.1, 8.8.4.4
Fixed by configuring Docker's DNS in daemon.json to use public DNS servers
Ollama containers were failing to download models due to DNS timeouts
Network "localai_default" showing "Resource still in use" when trying cleanup
Current status:

DNS resolution now working in containers
Restarted Ollama containers to retry downloads
Need to monitor if model downloads succeed
May need complete stack restart if issues persist

Initial Problem:

LocalAI stack failing due to DNS resolution problems in Docker containers
Containers couldn't resolve domain names, causing timeouts
Host system used systemd-resolved (127.0.0.53) which containers couldn't access
Solution Applied:

Configured Docker's DNS in daemon.json to use public DNS servers
Successfully fixed DNS resolution
Models (qwen2.5:7b-instruct and nomic-embed-text) were downloaded correctly
Current Problem:

Docker networking issue when restarting the stack
Error: "failed to set up container networking: network 30bebdc331dc423f594d6b5497739c04dd37a0a648114ae70b0bfd637e72f1ef not found"
Docker is trying to connect to a network that exists but with reference issues
Network "localai_default" shows as "Resource still in use" during cleanup attempts
Stack fails to start completely despite network pruning attempts
The system is in a state where DNS works but Docker networking is preventing proper container startup.

Ceci a r√©solu le probl√®me
```
Claude Sonnet 3.7
Thought for 8 seconds
I see multiple containers in various states using the localai_default network. The issue appears to be related to some containers in problematic states (especially the restarting Supabase pooler and created-but-not-started n8n).

Let's clean this up systematically:

Stop all running containers in this network:
bash
Copy Code
docker stop $(docker ps -q --filter network=localai_default)
Disconnect each container from the network:
bash
Copy Code
for container in $(docker ps -a -q --filter network=localai_default); do
  docker network disconnect -f localai_default $container
done
Now try removing the network:
bash
Copy Code
docker network rm localai_default
If you still encounter issues, try restarting Docker:
bash
Copy Code
sudo systemctl restart docker
Then restart your LocalAI stack with a fresh network configuration.
The key problem appears to be Supabase-pooler continuously restarting, which keeps the network in use. The forced disconnect should resolve this.
```
# Setting Up LocalAI Stack on a Docker VM

## Prerequisites
- A VM with Ubuntu/Debian (recommended 4+ CPU cores, 16GB+ RAM)
- Root access
- Public internet access

## 1. Update System
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y git curl
2. Install Docker
bash
Copy Code
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
Log out and back in to apply group changes.

3. Configure Docker DNS
Create or modify Docker daemon configuration:

bash
Copy Code
sudo mkdir -p /etc/docker
sudo nano /etc/docker/daemon.json
Add the following:

json
Copy Code
{
  "dns": ["8.8.8.8", "8.8.4.4"]
}
Restart Docker:

bash
Copy Code
sudo systemctl restart docker
4. Get LocalAI Stack
bash
Copy Code
git clone https://github.com/your-repo/local-ai-packaged.git
cd local-ai-packaged
5. Configure Environment
bash
Copy Code
cp .env.example .env
nano .env
Adjust settings as needed, particularly:

Model settings
Port mappings
Resource limits
6. Start the Stack
bash
Copy Code
python start_services.py --profile cpu
Available profiles: cpu, gpu-nvidia, gpu-amd, none

7. Pull Models
bash
Copy Code
docker exec -it ollama ollama pull qwen2.5:7b-instruct
docker exec -it ollama ollama pull nomic-embed-text
8. Verify Services
bash
Copy Code
docker ps
9. Accessing Services
OpenWebUI: http://your-vm-ip:3000
Flowise: http://your-vm-ip:3001
Supabase Studio: http://your-vm-ip:8000
10. Updating the Stack
To update all containers to their latest versions:

bash
Copy Code
# Stop all services
docker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml down

# Pull latest versions of all containers
docker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml pull

# Start services again with your desired profile
python start_services.py --profile <your-profile>
Replace <your-profile> with one of: cpu, gpu-nvidia, gpu-amd, or none.

Troubleshooting
DNS Issues
If containers have DNS problems:

Check Docker DNS configuration in daemon.json
Verify container networking by running ping google.com inside containers
Network Conflicts
If you encounter "network not found" or "resource in use" errors:

bash
Copy Code
# Stop all containers
docker stop $(docker ps -q --filter network=localai_default)

# Disconnect containers from network
for container in $(docker ps -a -q --filter network=localai_default); do
  docker network disconnect -f localai_default $container
done

# Remove network
docker network rm localai_default

# Restart Docker
sudo systemctl restart docker
Performance Issues
Adjust model sizes in .env
Monitor resources with docker stats
Consider using GPU acceleration if available
Basic Usage
Use OpenWebUI for chat with models
Configure Flowise for AI workflows
Use Supabase for data storage and vector search

The logs show a memory issue. Your VM doesn't have enough RAM to load the Qwen2.5 7B model:

```
error="model requires more system memory (5.4 GiB) than is available (4.5 GiB)"
```

You have several options:

1. **Add swap space** to your VM:
   ```bash
   sudo fallocate -l 8G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
   ```

2. **Use a smaller model** instead:
   ```bash
   docker exec -it ollama ollama pull phi3:mini
   # or
   docker exec -it ollama ollama pull mistral:instruct
   ```

3. **Free memory** by stopping unnecessary services:
   ```bash
   docker stop supabase-analytics supabase-imgproxy
   ```

4. **Increase VM RAM** to at least 8GB (ideally 16GB for comfortable use)

Try the swap solution first, then restart Ollama:
```bash
docker restart ollama
```
- http://host.docker.internal:11434/ --> ollama   // https://ollama.atthesametime.eu/
- http://host.docker.internal:6333/ -->  qdrant  //http://localhost:6333/  --> curl http://localhost:6333  dans hostinger
- https://searxng.atthesametime.eu/   http://localhost:8080/
- https://flowise.atthesametime.eu/   http://localhost:3001/
- https://supabase.atthesametime.eu/   http://localhost:5678/home/workflows
- https://openwebui.atthesametime.eu/      http://localhost:3000/
- https://n8n.atthesametime.eu/    http://localhost:5678/home/workflows

## IA Comment suivre le rithme ?
- Tout va tr√®s vite et pour ma^triser l'IA et ne pas √™tre seulement spectateur il faut une m√©thode, je propse le couper/coller
- Un acteur [Cole Melin](https://www.youtube.com/@ColeMedin) sur youtube, (cr√©ateur de bolt) travaille √† temps plein pour apporter sur la base de 2 vid√©os par semaine le r√©sultat de son travail. Il vise √† trouver des soutions g√©n√©ralements open source, et il est compl√®tement transparent sur ces propres travaux que l'on peut dupliquer .
- Ce travail de couper/coller demande n√©anmoins des efforts, mais c'est la meilleure fa√ßon d'apprendre √† apprendre , en √©tant acteur.
- J'ai ainsi dupliquer , temps en local que sur Hostinger avec mon domaine atthesametime.eu un stack qui correspond √† l'√©tat de l'art actuel avec
    - n8n : on peut automaiser pr√®s de 500 t√¢ches , elles sont accessibles via des nodes webhooks qui fournissent les url d'acc√®s et en cr√©ant les cr√©dentials requis
    - flowise: qui en nos code permet de cr√©er des agents
    - openwebui : qui permet d'interagir avec notre stack en no code aavec un interface rsssemblant √† celui de chatGPT
    - searxng pour les recherches sur le net
    - supabase et GDrant pour base de donn√©es
    - ollama pour les llm locaux.J'utilise aussi openrouter pour des llm plus performants (certains sont gratuits comme mistralai/mistral-small-3.1-24b-instruct:free 
    - caddy pour le cryptage
 
- Le portage sur Hostinger avec une configuration CPU 2 cores 8GB, 100GB ne co√ªte que ~ 6 ‚Ç¨ /mois et permet de partager le stack sur un r√©seau d√©localis√©    
-   
