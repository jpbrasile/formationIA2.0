# formationIA2.0

## Formation √† l'IA en 2024: 

Dans le tableau ci-apr√®s: 3 niveaux de formation : D√©butant, interm√©diaire et avanc√©
- **Quels outils ?** : Ceux √† ma√Ætriser pour √™tre efficace:  Halte aux probl√®mes ! Euh non !  "**Alt A <Probl√®me>!**" et Harpa.ai vous r√©pondra !
- **Le prompt** : Comment parler avec le chatbot pour que sa r√©ponse soit pertinente ?
- **Fournir aux LLM nos propres donn√©es** : Comment le chatbot peut prendre en compte mes donn√©es ?
- **Acc√®s √† Internet**: Comment faire pour qu'il prenne les donn√©es pertinantes sur le cloud ?
- **G√©rer le Contexte**: Comment composer avec sa m√©moire vive qui ne peut accumuler qu'un nombre fini de donn√©es ?
- **Au del√† de l'√©crit** : Comment travailler avec des donn√©es non textuelles (images, son ... ) tant en entr√©e qu'en sortie ?
- **L'acc√®s aux outils externes**: Comment faire que le chatbot acc√®de √† des ressources externes disponibles sur le web ?
- **Chatbots sp√©cialis√©s** : Comment cr√©er des chatbots sp√©cialis√©s pour remplir certaines t√¢ches ?
- **Travail en √©quipe**: Comment cr√©er des chatbots travaillant en √©quipe
- **L'IA apprend toute seule** : Comment faire pour que les Chatbot apprennent de leurs erreurs ?

| Niveau        | Objectif                              | Quels outils  ?                           | [Le prompt](https://github.com/jpbrasile/formationIA2.0/wiki/4.-Le-prompting)                                           | [Fournir aux LLM nos propres donn√©es](https://github.com/jpbrasile/formationIA2.0/wiki/6.-Fournir-aux-LLM-nos-propres-donn%C3%A9es)                                               | [L'Acc√®s √† Internet](https://github.com/jpbrasile/formationIA2.0/wiki/L'acc%C3%A8s-%C3%A0-internet.md)                                            | G√©rer le contexte                                             | Au del√† de l'√©crit                                         | L'acc√®s aux outils externes                                               | Chatbots sp√©cialis√©s                                              | Travail en √©quipe                                           | L'IA apprend toute seule                                               |
|---------------|---------------------------------------|-----------------------------------------|------------------------------------------------------|------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------|---------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| D√©butant      | Utiliser l'IA         | [Nos outils:](https://github.com/jpbrasile/formationIA2.0/wiki/01:-Comment-disposer-d'outils-qui-font-tout-pour-vous-%3F)  [ChatGPT](https://chat.openai.com/), [Copilot](https://copilot.microsoft.com/?culture=fr-fr&country=fr), [Harpa](https://harpa.ai/), [Perplexity](https://www.perplexity.ai/), [Canva](https://www.canva.com/)              | [Les bases](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/3-%20le%20prompting.md) |[Avec nos outils](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/4-%20Prise%20en%20compte%20de%20mes%20donn%C3%A9es.md)            | Avec nos outils              |  Un prompt pour demander la synth√®se   | Copilot (dessin) et outils en ligne| Outils en ligne          |  |                |
| Interm√©diaire | Ma√Ætriser l'IA          | Choisir son LLM open source           | Formation au prompting   |Technique d'embedding | Formation au scraping                    | MEMGPT et LongGPT             | LLAVA1.5 et ComphyUI | Langchain, Gorilla            | emploi des GPTs openAI        |     AutoGen         |   |
| Avanc√©        | Cr√©er avec l'IA       | Finetuning, Cr√©ation de MOE | Prompt optimis√© par programmation                   | Cr√©ation de base de donn√©es locales       | AgentSearch et Wiki search | Gestion avanc√©e du contexte (compactage)                        | D√©veloppement de solutions multimodales personnalis√©es | Conception d'API robustes pour des applications √† grande √©chelle | Utilisation de GPT-4 et autres mod√®les avanc√©s     | D√©veloppement d'agents autonomes capables d'apprentissage continu | Strat√©gies pour le d√©veloppement de talents en IA et gestion des changements technologiques |

## ChatGPT C'est quoi ? : 
- [00:00](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=0s) ü§ñ Qu'est-ce que ChatGPT ? [Large Language Model Base: un LLM √† la maternelle](https://github.com/jpbrasile/formationIA2.0/wiki/1.-LLM%E2%80%90Base) 

  - ChatGPT est une machine √† approximer qui fournit des r√©ponses bas√©es sur ce qu'il a appris.
  - Il est efficace pour interpoler mais peut fournir de fausses r√©ponses en l'absence de donn√©es suffisantes.
  - L'apprentissage de ChatGPT n√©cessite l'ajustement de ses param√®tres en fonction des donn√©es d'entr√©e, et il a utilis√© des milliards de donn√©es pour ajuster ses param√®tres.

- [01:11](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=71s) üìö Comment instruire ChatGPT ? : [Le LLM √† l'√©cole](https://github.com/jpbrasile/formationIA2.0/wiki/2.-LLM%E2%80%90Instruct) 
  - Pour instruire ChatGPT, il faut lui donner des directives sur son comportement.
  - Alimenter la machine avec une nouvelle base de donn√©es de type question-r√©ponse lui permet de mimer ce type de r√©sultat.
  - Des gardes-fous sont n√©cessaires pour censurer certaines r√©ponses et inculquer les bonnes mani√®res.

- [02:09](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=129s) üíª Implantation de ChatGPT

  - ChatGPT est principalement disponible en ligne via le Cloud, en raison de son co√ªt de d√©veloppement.
  - Le contr√¥le sur l'utilisation de ChatGPT est difficile, ce qui soul√®ve des pr√©occupations concernant la divulgation d'informations sensibles.
  - Un mouvement open source travaille sur des versions plus l√©g√®res de ChatGPT pour des utilisations locales.

- [03:18](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=198s) üß† La taille et le contexte des LLM : [Le LLM peut soutenir une conversation](https://github.com/jpbrasile/formationIA2.0/wiki/3.-LLM%E2%80%90Chat) 

  - Les LLM (Large Language Models) sont en constante √©volution pour devenir plus l√©gers tout en maintenant leur performance.
  - La taille des LLM est mesur√©e en milliards de bytes, et des versions plus compactes sont d√©velopp√©es.
  - Le contexte, ou m√©moire √† court terme, est crucial pour stocker des informations pertinentes lors de l'interaction avec un LLM.
