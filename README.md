# FormationIA2.0

<details>
<summary><b>Qu'est-ce que l'IA peut vous rapporter ?</b></summary>
<p>Ce document est intéressant car il explore l'impact réel des Modèles de Langage à Grande Échelle (LLM), comme GPT-4, sur des tâches complexes et riches en connaissances. L'étude, menée avec le Boston Consulting Group, impliquait 758 consultants et visait à comprendre comment l'IA peut améliorer la performance humaine dans un contexte professionnel.</p>
<p>Principales conclusions de l'étude :</p>
<ul>
    <li><strong>Productivité et Qualité Accrues</strong> : Les consultants utilisant l'IA étaient nettement plus productifs et produisaient un travail de meilleure qualité. En moyenne, ils ont complété 12,2 % de tâches en plus et ce, 25,1 % plus rapidement. De plus, la qualité de leur travail était supérieure de plus de 40 % par rapport à ceux n'utilisant pas l'IA.</li>
    <li><strong>Bénéfices à Tous les Niveaux de Compétences</strong> : L'étude a révélé que l'augmentation par l'IA profitait significativement aux consultants à tous les niveaux de compétence. Ceux en dessous du seuil de performance moyen ont vu leur performance augmenter de 43 %, tandis que ceux au-dessus ont amélioré de 17 %.</li>
    <li><strong>Limites de l'IA</strong> : L'étude a également identifié des tâches actuellement hors de portée de l'IA. Pour ces tâches, les consultants utilisant l'IA étaient 19 points de pourcentage moins susceptibles de produire des solutions correctes par rapport à ceux sans accès à l'IA.</li>
    <li><strong>Modèles d'Intégration de l'IA</strong> : L'étude a observé deux modèles distincts dans la façon dont les consultants intégraient l'IA dans leur travail :
        <ul>
            <li><strong>Centaures</strong> : Certains consultants agissaient comme des Centaures, divisant les tâches entre eux et l'IA, déléguant certaines activités à l'IA.</li>
            <li><strong>Cyborgs</strong> : D'autres agissaient plus comme des Cyborgs, intégrant complètement leur flux de travail avec l'IA et interagissant continuellement avec elle.</li>
        </ul>
    </li>
</ul>
<p>Pour plus de détails, consultez le document complet : <a href="https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf">Lien vers l'étude</a>.</p>
</details>


<details>
  <summary> <b>Les astuces à utiliser</b></summary>
  <br> 
  <details>
    <summary> Impression d'écran sous windows?</summary>
   
    Touche Windows+MAj+S
  </details>
  <details>
    <summary> Insérer l'image dans GitHub</summary>

    Télécharger l'image puis simple upload au point de la page wiki où l'on veut mettre l'image
  </details>
  <details>
    <summary> Pour obtenir de chatGPT un format markdown à couper/coller </summary>
  
    "Fournis le contenu formaté en Markdown, présenté sous forme de chaîne de caractères " 
  </details>


   <details>
    <summary>accéder à toutes les commandes d'Harpa </summary>

   il suffit de mettre "/" dans le chat; ex: "/clear": supprime l'historique des chats.
  </details>
</details>
  
</details>


## Formation à l'IA en 2024: 

Dans le tableau ci-après: 3 niveaux de formation : Débutant, intermédiaire et avancé
- **Quels outils ?** : Ceux à maîtriser pour être efficace:  Halte aux problèmes ! Euh non !  "**Alt A <Problème>!**" et Harpa.ai vous répondra !
- **Le prompt** : Comment parler avec le chatbot pour que sa réponse soit pertinente ?
- **Fournir aux LLM nos propres données** : Comment le chatbot peut prendre en compte mes données ?
- **Accès à Internet**: Comment faire pour qu'il prenne les données pertinantes sur le cloud ?
- **Gérer le Contexte**: Comment composer avec sa mémoire vive qui ne peut accumuler qu'un nombre fini de données ?
- **Au delà de l'écrit** : Comment travailler avec des données non textuelles (images, son ... ) tant en entrée qu'en sortie ?
- **L'accès aux outils externes**: Comment faire que le chatbot accède à des ressources externes disponibles sur le web ?
- **Chatbots spécialisés** : Comment créer des chatbots spécialisés pour remplir certaines tâches ?
- **Travail en équipe**: Comment créer des chatbots travaillant en équipe
- **L'IA apprend toute seule** : Comment faire pour que les Chatbot apprennent de leurs erreurs ?

| Niveau        | Objectif                              | [Quels outils  ?](https://github.com/jpbrasile/formationIA2.0/wiki/Installation-des-outils.md)                           | [Le prompt](https://github.com/jpbrasile/formationIA2.0/wiki/4.-Le-prompting)                                           | [Fournir aux LLM nos propres données](https://github.com/jpbrasile/formationIA2.0/wiki/6.-Fournir-aux-LLM-nos-propres-donn%C3%A9es)                                               | [L'Accès à Internet](https://github.com/jpbrasile/formationIA2.0/wiki/L'acc%C3%A8s-%C3%A0-internet.md)                                            | [Gérer le contexte](https://github.com/jpbrasile/formationIA2.0/wiki/5.-Gestion-du-contexte)                                             | [Au delà de l'écrit](https://github.com/jpbrasile/formationIA2.0/wiki/9.-Les-LLM-multimodaux-(MLLM))                                         | [L'accès aux outils externes](https://github.com/jpbrasile/formationIA2.0/wiki/8.-L%E2%80%99Acc%C3%A8s-aux-API)                                               | [Chatbots spécialisés](https://github.com/jpbrasile/formationIA2.0/wiki/A.-Les-GPTs)                                              | [Travail en équipe](https://github.com/jpbrasile/formationIA2.0/wiki/B.-Les-agents)                                           | [L'IA apprend toute seule](https://github.com/jpbrasile/formationIA2.0/wiki/C.-L%E2%80%99apprentissage-par-renforcement-:)                                               |
|---------------|---------------------------------------|-----------------------------------------|------------------------------------------------------|------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------|---------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| Débutant      | [Utiliser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/1-%20prendre%20des%20notes.md) [challenge](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/challenge.md)       | [Nos outils:](https://github.com/jpbrasile/formationIA2.0/wiki/01:-Comment-disposer-d'outils-qui-font-tout-pour-vous-%3F)  [ChatGPT](https://chat.openai.com/), [Copilot](https://copilot.microsoft.com/?culture=fr-fr&country=fr), [Harpa](https://harpa.ai/), [Perplexity](https://www.perplexity.ai/), [Canva](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/canva.md)           [ GitHub, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/github.md) [Capcut](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/capcut.md)  | [Les bases](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/3-%20le%20prompting.md) |Avec nos outils       | Avec nos outils              |  Un prompt pour demander la synthèse   | Copilot (dessin) et [outils en ligne, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/multimodal.md)| [Runway](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/Runway.md) [Outils en ligne](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/5-%20API.md)          |  |                |
| Intermédiaire | [Maîtriser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)  [DeepLearning courses](https://www.deeplearning.ai/short-courses/)        | [Quel LLM ? ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhatLLM.md) [MixtralReplicate, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Replicate.md)    (MistralMédium](https://jeanviet.fr/mistral-medium/)        | [MetricMule et Formation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/le%20prompting.md)    |[Pinecone,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/RAG.md) [voiceflow,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)[Haystack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md) | [GPT Crawler,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/scraping.md) [GPT-Researcher, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPt-Researcher.md) [OnLine Shop](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/OnLineShop.md)                   | [MEMGPT,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/context.md)             | [ComfyUI,LLAVA,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/multimodal.md) [firellava](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/firellava.md) [Local ChatGPT, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Local%20ChatGPT.md) [WhisperSpeech, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhisperSpeech.md) [fuyu](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/fuyu.md)| [Langchain,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/API.md) , [Colab, HF...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)   ,[open interpreter](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Open%20Interpreter.md) [Phind, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Phind.md) [wolfram, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/programWithWolfram.md) [taskweaver, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/taskweaver.md) [AIDER, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/AIDER.md) [CURSOR](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/CURSOR.md)    | [emploi des GPTs openAI,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPTs.md) [voiceflow](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)       |     [AutoGen, CrewAI, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Agent.md) [n8n](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/n8n.md)       |   |
| Avancé        | [Créer avec l'IA](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/challenges.md),[aller plus loin](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Apprendre%20l'IA%20en%202024.md)       |[+vite](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Etat%20de%20l'art.md),[>GPT4](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Quel%20LLM.md) [Finetuning,Quantification...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/les%20outils.md) Création de MOE | [Prompt optimisé par programmation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/prompting.md)                   | Création de base de données locales       | AgentSearch et Wiki search | Gestion avancée du contexte (compactage)                        | [animation 3D, audiobook...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/multimodal.md) | Conception d'API robustes pour des applications à grande échelle | [Screen2Code, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/GPTs.md) [Crack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Crack.md)    | Développement d'agents autonomes capables d'apprentissage continu | Stratégies pour le développement de talents en IA et gestion des changements technologiques |

## ChatGPT C'est quoi ? : 
- [00:00](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=0s) 🤖 Qu'est-ce que ChatGPT ? [Large Language Model Base: un LLM à la maternelle](https://github.com/jpbrasile/formationIA2.0/wiki/1.-LLM%E2%80%90Base) 

  - ChatGPT est une machine à approximer qui fournit des réponses basées sur ce qu'il a appris.
  - Il est efficace pour interpoler mais peut fournir de fausses réponses en l'absence de données suffisantes.
  - L'apprentissage de ChatGPT nécessite l'ajustement de ses paramètres en fonction des données d'entrée, et il a utilisé des milliards de données pour ajuster ses paramètres.

- [01:11](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=71s) 📚 Comment instruire ChatGPT ? : [Le LLM à l'école](https://github.com/jpbrasile/formationIA2.0/wiki/2.-LLM%E2%80%90Instruct) 
  - Pour instruire ChatGPT, il faut lui donner des directives sur son comportement.
  - Alimenter la machine avec une nouvelle base de données de type question-réponse lui permet de mimer ce type de résultat.
  - Des gardes-fous sont nécessaires pour censurer certaines réponses et inculquer les bonnes manières.

- [02:09](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=129s) 💻 Implantation de ChatGPT

  - ChatGPT est principalement disponible en ligne via le Cloud, en raison de son coût de développement.
  - Le contrôle sur l'utilisation de ChatGPT est difficile, ce qui soulève des préoccupations concernant la divulgation d'informations sensibles.
  - Un mouvement open source travaille sur des versions plus légères de ChatGPT pour des utilisations locales.

- [03:18](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=198s) 🧠 La taille et le contexte des LLM : [Le LLM peut soutenir une conversation](https://github.com/jpbrasile/formationIA2.0/wiki/3.-LLM%E2%80%90Chat) 

  - Les LLM (Large Language Models) sont en constante évolution pour devenir plus légers tout en maintenant leur performance.
  - La taille des LLM est mesurée en milliards de bytes, et des versions plus compactes sont développées.
  - Le contexte, ou mémoire à court terme, est crucial pour stocker des informations pertinentes lors de l'interaction avec un LLM.
 
  ## L'open-source proche de GPT4
  ![Capture d'écran 2024-01-24 155607](https://github.com/jpbrasile/formationIA2.0/assets/8331027/0ef1137e-e79c-405d-8816-cad6a82e41b6)

  ## Un stack local ou déployable sur hostinger domaine: atthesametime.eu
  -  fait à partir de [Colin](https://github.com/coleam00/local-ai-packaged)
  -  url:
      - n8N:    http://localhost:5678/
      - flowise: http://localhost:3001/
      - Searxng: http://localhost:8080/
      - openrouter: https://openrouter.ai/
      - openwebui: http://localhost:3000/
      - qdrant: http://localhost:6333/
      - caddy avec
          -  N8N_HOSTNAME=${N8N_HOSTNAME:-":8001"}
          - WEBUI_HOSTNAME=${WEBUI_HOSTNAME:-":8002"}
          - FLOWISE_HOSTNAME=${FLOWISE_HOSTNAME:-":8003"}
          - OLLAMA_HOSTNAME=${OLLAMA_HOSTNAME:-":8004"}
          - SUPABASE_HOSTNAME=${SUPABASE_HOSTNAME:-":8005"}
          - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-":8006"}
          - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL:-internal}
        - ollama: http://localhost:11434
- hostinger : systeme d'exploitation avec docker (application)
    - J'ai rajouté en local:
  ```
    environment:
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true 
  ```
  dans docker-compose.yml pour n8n et n8n-import

  !!! : un point important pour le déploiement :il y a des incompatibilité de parefeu entre docker et ufw, donc faire
  ```
  # Allow traffic within Docker's internal network
sudo ufw allow in on docker0
sudo ufw allow out on docker0
```

Issue :Issue: LocalAI stack failing to start properly due to DNS resolution problems in Docker containers.

Findings:

Docker containers couldn't resolve domain names (DNS timeout)
Host system uses systemd-resolved (127.0.0.53) which containers can't access
Hostinger VPS with DNS servers: 89.116.146.10, 1.1.1.1, 8.8.4.4
Fixed by configuring Docker's DNS in daemon.json to use public DNS servers
Ollama containers were failing to download models due to DNS timeouts
Network "localai_default" showing "Resource still in use" when trying cleanup
Current status:

DNS resolution now working in containers
Restarted Ollama containers to retry downloads
Need to monitor if model downloads succeed
May need complete stack restart if issues persist

Initial Problem:

LocalAI stack failing due to DNS resolution problems in Docker containers
Containers couldn't resolve domain names, causing timeouts
Host system used systemd-resolved (127.0.0.53) which containers couldn't access
Solution Applied:

Configured Docker's DNS in daemon.json to use public DNS servers
Successfully fixed DNS resolution
Models (qwen2.5:7b-instruct and nomic-embed-text) were downloaded correctly
Current Problem:

Docker networking issue when restarting the stack
Error: "failed to set up container networking: network 30bebdc331dc423f594d6b5497739c04dd37a0a648114ae70b0bfd637e72f1ef not found"
Docker is trying to connect to a network that exists but with reference issues
Network "localai_default" shows as "Resource still in use" during cleanup attempts
Stack fails to start completely despite network pruning attempts
The system is in a state where DNS works but Docker networking is preventing proper container startup.

Ceci a résolu le problème
```
Claude Sonnet 3.7
Thought for 8 seconds
I see multiple containers in various states using the localai_default network. The issue appears to be related to some containers in problematic states (especially the restarting Supabase pooler and created-but-not-started n8n).

Let's clean this up systematically:

Stop all running containers in this network:
bash
Copy Code
docker stop $(docker ps -q --filter network=localai_default)
Disconnect each container from the network:
bash
Copy Code
for container in $(docker ps -a -q --filter network=localai_default); do
  docker network disconnect -f localai_default $container
done
Now try removing the network:
bash
Copy Code
docker network rm localai_default
If you still encounter issues, try restarting Docker:
bash
Copy Code
sudo systemctl restart docker
Then restart your LocalAI stack with a fresh network configuration.
The key problem appears to be Supabase-pooler continuously restarting, which keeps the network in use. The forced disconnect should resolve this.
```
# Setting Up LocalAI Stack on a Docker VM

## Prerequisites
- A VM with Ubuntu/Debian (recommended 4+ CPU cores, 16GB+ RAM)
- Root access
- Public internet access

## 1. Update System
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y git curl
2. Install Docker
bash
Copy Code
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
Log out and back in to apply group changes.

3. Configure Docker DNS
Create or modify Docker daemon configuration:

bash
Copy Code
sudo mkdir -p /etc/docker
sudo nano /etc/docker/daemon.json
Add the following:

json
Copy Code
{
  "dns": ["8.8.8.8", "8.8.4.4"]
}
Restart Docker:

bash
Copy Code
sudo systemctl restart docker
4. Get LocalAI Stack
bash
Copy Code
git clone https://github.com/your-repo/local-ai-packaged.git
cd local-ai-packaged
5. Configure Environment
bash
Copy Code
cp .env.example .env
nano .env
Adjust settings as needed, particularly:

Model settings
Port mappings
Resource limits
6. Start the Stack
bash
Copy Code
python start_services.py --profile cpu
Available profiles: cpu, gpu-nvidia, gpu-amd, none

7. Pull Models
bash
Copy Code
docker exec -it ollama ollama pull qwen2.5:7b-instruct
docker exec -it ollama ollama pull nomic-embed-text
8. Verify Services
bash
Copy Code
docker ps
9. Accessing Services
OpenWebUI: http://your-vm-ip:3000
Flowise: http://your-vm-ip:3001
Supabase Studio: http://your-vm-ip:8000
10. Updating the Stack
To update all containers to their latest versions:

bash
Copy Code
# Stop all services
docker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml down

# Pull latest versions of all containers
docker compose -p localai -f docker-compose.yml -f supabase/docker/docker-compose.yml pull

# Start services again with your desired profile
python start_services.py --profile <your-profile>
Replace <your-profile> with one of: cpu, gpu-nvidia, gpu-amd, or none.

Troubleshooting
DNS Issues
If containers have DNS problems:

Check Docker DNS configuration in daemon.json
Verify container networking by running ping google.com inside containers
Network Conflicts
If you encounter "network not found" or "resource in use" errors:

bash
Copy Code
# Stop all containers
docker stop $(docker ps -q --filter network=localai_default)

# Disconnect containers from network
for container in $(docker ps -a -q --filter network=localai_default); do
  docker network disconnect -f localai_default $container
done

# Remove network
docker network rm localai_default

# Restart Docker
sudo systemctl restart docker
Performance Issues
Adjust model sizes in .env
Monitor resources with docker stats
Consider using GPU acceleration if available
Basic Usage
Use OpenWebUI for chat with models
Configure Flowise for AI workflows
Use Supabase for data storage and vector search

The logs show a memory issue. Your VM doesn't have enough RAM to load the Qwen2.5 7B model:

```
error="model requires more system memory (5.4 GiB) than is available (4.5 GiB)"
```

You have several options:

1. **Add swap space** to your VM:
   ```bash
   sudo fallocate -l 8G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
   ```

2. **Use a smaller model** instead:
   ```bash
   docker exec -it ollama ollama pull phi3:mini
   # or
   docker exec -it ollama ollama pull mistral:instruct
   ```

3. **Free memory** by stopping unnecessary services:
   ```bash
   docker stop supabase-analytics supabase-imgproxy
   ```

4. **Increase VM RAM** to at least 8GB (ideally 16GB for comfortable use)

Try the swap solution first, then restart Ollama:
```bash
docker restart ollama
```
- http://host.docker.internal:11434/ --> ollama   // https://ollama.atthesametime.eu/
- http://host.docker.internal:6333/ -->  qdrant  //http://localhost:6333/  --> curl http://localhost:6333  dans hostinger
- https://searxng.atthesametime.eu/   http://localhost:8080/
- https://flowise.atthesametime.eu/   http://localhost:3001/
- https://supabase.atthesametime.eu/   http://localhost:5678/home/workflows
- https://openwebui.atthesametime.eu/      http://localhost:3000/
- https://n8n.atthesametime.eu/    http://localhost:5678/home/workflows

## IA Comment suivre le rithme ?
- Tout va très vite et pour ma^triser l'IA et ne pas être seulement spectateur il faut une méthode, je propse le couper/coller
- Un acteur [Cole Melin](https://www.youtube.com/@ColeMedin) sur youtube, (créateur de bolt) travaille à temps plein pour apporter sur la base de 2 vidéos par semaine le résultat de son travail. Il vise à trouver des soutions généralements open source, et il est complètement transparent sur ces propres travaux que l'on peut dupliquer .
- Ce travail de couper/coller demande néanmoins des efforts, mais c'est la meilleure façon d'apprendre à apprendre , en étant acteur.
- J'ai ainsi dupliquer , temps en local que sur Hostinger avec mon domaine atthesametime.eu un stack qui correspond à l'état de l'art actuel avec
    - n8n : on peut automaiser près de 500 tâches , elles sont accessibles via des nodes webhooks qui fournissent les url d'accès et en créant les crédentials requis
    - flowise: qui en nos code permet de créer des agents
    - openwebui : qui permet d'interagir avec notre stack en no code aavec un interface rsssemblant à celui de chatGPT
    - searxng pour les recherches sur le net
    - supabase et GDrant pour base de données
    - ollama pour les llm locaux.J'utilise aussi openrouter pour des llm plus performants (certains sont gratuits comme mistralai/mistral-small-3.1-24b-instruct:free 
    - caddy pour le cryptage
 
- Le portage sur Hostinger avec une configuration CPU 2 cores 8GB, 100GB ne coûte que ~ 6 € /mois et permet de partager le stack sur un réseau délocalisé    
-   
