# FormationIA2.0

<details>
<summary><b>Qu'est-ce que l'IA peut vous rapporter ?</b></summary>
<p>Ce document est int√©ressant car il explore l'impact r√©el des Mod√®les de Langage √† Grande √âchelle (LLM), comme GPT-4, sur des t√¢ches complexes et riches en connaissances. L'√©tude, men√©e avec le Boston Consulting Group, impliquait 758 consultants et visait √† comprendre comment l'IA peut am√©liorer la performance humaine dans un contexte professionnel.</p>
<p>Principales conclusions de l'√©tude :</p>
<ul>
    <li><strong>Productivit√© et Qualit√© Accrues</strong> : Les consultants utilisant l'IA √©taient nettement plus productifs et produisaient un travail de meilleure qualit√©. En moyenne, ils ont compl√©t√© 12,2 % de t√¢ches en plus et ce, 25,1 % plus rapidement. De plus, la qualit√© de leur travail √©tait sup√©rieure de plus de 40 % par rapport √† ceux n'utilisant pas l'IA.</li>
    <li><strong>B√©n√©fices √† Tous les Niveaux de Comp√©tences</strong> : L'√©tude a r√©v√©l√© que l'augmentation par l'IA profitait significativement aux consultants √† tous les niveaux de comp√©tence. Ceux en dessous du seuil de performance moyen ont vu leur performance augmenter de 43 %, tandis que ceux au-dessus ont am√©lior√© de 17 %.</li>
    <li><strong>Limites de l'IA</strong> : L'√©tude a √©galement identifi√© des t√¢ches actuellement hors de port√©e de l'IA. Pour ces t√¢ches, les consultants utilisant l'IA √©taient 19 points de pourcentage moins susceptibles de produire des solutions correctes par rapport √† ceux sans acc√®s √† l'IA.</li>
    <li><strong>Mod√®les d'Int√©gration de l'IA</strong> : L'√©tude a observ√© deux mod√®les distincts dans la fa√ßon dont les consultants int√©graient l'IA dans leur travail :
        <ul>
            <li><strong>Centaures</strong> : Certains consultants agissaient comme des Centaures, divisant les t√¢ches entre eux et l'IA, d√©l√©guant certaines activit√©s √† l'IA.</li>
            <li><strong>Cyborgs</strong> : D'autres agissaient plus comme des Cyborgs, int√©grant compl√®tement leur flux de travail avec l'IA et interagissant continuellement avec elle.</li>
        </ul>
    </li>
</ul>
<p>Pour plus de d√©tails, consultez le document complet : <a href="https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf">Lien vers l'√©tude</a>.</p>
</details>


<details>
  <summary> <b>Les astuces √† utiliser</b></summary>
  <br> 
  <details>
    <summary> Impression d'√©cran sous windows?</summary>
   
    Touche Windows+MAj+S
  </details>
  <details>
    <summary> Ins√©rer l'image dans GitHub</summary>

    T√©l√©charger l'image puis simple upload au point de la page wiki o√π l'on veut mettre l'image
  </details>
  <details>
    <summary> Pour obtenir de chatGPT un format markdown √† couper/coller </summary>
  
    "Fournis le contenu format√© en Markdown, pr√©sent√© sous forme de cha√Æne de caract√®res " 
  </details>


   <details>
    <summary>acc√©der √† toutes les commandes d'Harpa </summary>

   il suffit de mettre "/" dans le chat; ex: "/clear": supprime l'historique des chats.
  </details>
</details>
  
</details>


## Formation √† l'IA en 2024: 

Dans le tableau ci-apr√®s: 3 niveaux de formation : D√©butant, interm√©diaire et avanc√©
- **Quels outils ?** : Ceux √† ma√Ætriser pour √™tre efficace:  Halte aux probl√®mes ! Euh non !  "**Alt A <Probl√®me>!**" et Harpa.ai vous r√©pondra !
- **Le prompt** : Comment parler avec le chatbot pour que sa r√©ponse soit pertinente ?
- **Fournir aux LLM nos propres donn√©es** : Comment le chatbot peut prendre en compte mes donn√©es ?
- **Acc√®s √† Internet**: Comment faire pour qu'il prenne les donn√©es pertinantes sur le cloud ?
- **G√©rer le Contexte**: Comment composer avec sa m√©moire vive qui ne peut accumuler qu'un nombre fini de donn√©es ?
- **Au del√† de l'√©crit** : Comment travailler avec des donn√©es non textuelles (images, son ... ) tant en entr√©e qu'en sortie ?
- **L'acc√®s aux outils externes**: Comment faire que le chatbot acc√®de √† des ressources externes disponibles sur le web ?
- **Chatbots sp√©cialis√©s** : Comment cr√©er des chatbots sp√©cialis√©s pour remplir certaines t√¢ches ?
- **Travail en √©quipe**: Comment cr√©er des chatbots travaillant en √©quipe
- **L'IA apprend toute seule** : Comment faire pour que les Chatbot apprennent de leurs erreurs ?

| Niveau        | Objectif                              | [Quels outils  ?](https://github.com/jpbrasile/formationIA2.0/wiki/Installation-des-outils.md)                           | [Le prompt](https://github.com/jpbrasile/formationIA2.0/wiki/4.-Le-prompting)                                           | [Fournir aux LLM nos propres donn√©es](https://github.com/jpbrasile/formationIA2.0/wiki/6.-Fournir-aux-LLM-nos-propres-donn%C3%A9es)                                               | [L'Acc√®s √† Internet](https://github.com/jpbrasile/formationIA2.0/wiki/L'acc%C3%A8s-%C3%A0-internet.md)                                            | [G√©rer le contexte](https://github.com/jpbrasile/formationIA2.0/wiki/5.-Gestion-du-contexte)                                             | [Au del√† de l'√©crit](https://github.com/jpbrasile/formationIA2.0/wiki/9.-Les-LLM-multimodaux-(MLLM))                                         | [L'acc√®s aux outils externes](https://github.com/jpbrasile/formationIA2.0/wiki/8.-L%E2%80%99Acc%C3%A8s-aux-API)                                               | [Chatbots sp√©cialis√©s](https://github.com/jpbrasile/formationIA2.0/wiki/A.-Les-GPTs)                                              | [Travail en √©quipe](https://github.com/jpbrasile/formationIA2.0/wiki/B.-Les-agents)                                           | [L'IA apprend toute seule](https://github.com/jpbrasile/formationIA2.0/wiki/C.-L%E2%80%99apprentissage-par-renforcement-:)                                               |
|---------------|---------------------------------------|-----------------------------------------|------------------------------------------------------|------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------|---------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| D√©butant      | [Utiliser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/1-%20prendre%20des%20notes.md) [challenge](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/challenge.md)       | [Nos outils:](https://github.com/jpbrasile/formationIA2.0/wiki/01:-Comment-disposer-d'outils-qui-font-tout-pour-vous-%3F)  [ChatGPT](https://chat.openai.com/), [Copilot](https://copilot.microsoft.com/?culture=fr-fr&country=fr), [Harpa](https://harpa.ai/), [Perplexity](https://www.perplexity.ai/), [Canva](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/canva.md)           [ GitHub, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/github.md) [Capcut](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/capcut.md)  | [Les bases](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/3-%20le%20prompting.md) |Avec nos outils       | Avec nos outils              |  Un prompt pour demander la synth√®se   | Copilot (dessin) et [outils en ligne, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/multimodal.md)| [Runway](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/Runway.md) [Outils en ligne](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/5-%20API.md)          |  |                |
| Interm√©diaire | [Ma√Ætriser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)  [DeepLearning courses](https://www.deeplearning.ai/short-courses/)        | [Quel LLM ? ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhatLLM.md) [MixtralReplicate, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Replicate.md)    (MistralM√©dium](https://jeanviet.fr/mistral-medium/)        | [MetricMule et Formation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/le%20prompting.md)    |[Pinecone,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/RAG.md) [voiceflow,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)[Haystack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md) | [GPT Crawler,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/scraping.md) [GPT-Researcher, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPt-Researcher.md) [OnLine Shop](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/OnLineShop.md)                   | [MEMGPT,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/context.md)             | [ComfyUI,LLAVA,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/multimodal.md) [firellava](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/firellava.md) [Local ChatGPT, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Local%20ChatGPT.md) [WhisperSpeech, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhisperSpeech.md) [fuyu](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/fuyu.md)| [Langchain,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/API.md) , [Colab, HF...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)   ,[open interpreter](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Open%20Interpreter.md) [Phind, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Phind.md) [wolfram, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/programWithWolfram.md) [taskweaver, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/taskweaver.md) [AIDER, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/AIDER.md) [CURSOR](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/CURSOR.md)    | [emploi des GPTs openAI,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPTs.md) [voiceflow](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)       |     [AutoGen, CrewAI, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Agent.md) [n8n](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/n8n.md)       |   |
| Avanc√©        | [Cr√©er avec l'IA](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/challenges.md),[aller plus loin](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Apprendre%20l'IA%20en%202024.md)       |[+vite](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Etat%20de%20l'art.md),[>GPT4](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Quel%20LLM.md) [Finetuning,Quantification...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/les%20outils.md) Cr√©ation de MOE | [Prompt optimis√© par programmation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/prompting.md)                   | Cr√©ation de base de donn√©es locales       | AgentSearch et Wiki search | Gestion avanc√©e du contexte (compactage)                        | [animation 3D, audiobook...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/multimodal.md) | Conception d'API robustes pour des applications √† grande √©chelle | [Screen2Code, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/GPTs.md) [Crack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Crack.md)    | D√©veloppement d'agents autonomes capables d'apprentissage continu | Strat√©gies pour le d√©veloppement de talents en IA et gestion des changements technologiques |

## ChatGPT C'est quoi ? : 
- [00:00](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=0s) ü§ñ Qu'est-ce que ChatGPT ? [Large Language Model Base: un LLM √† la maternelle](https://github.com/jpbrasile/formationIA2.0/wiki/1.-LLM%E2%80%90Base) 

  - ChatGPT est une machine √† approximer qui fournit des r√©ponses bas√©es sur ce qu'il a appris.
  - Il est efficace pour interpoler mais peut fournir de fausses r√©ponses en l'absence de donn√©es suffisantes.
  - L'apprentissage de ChatGPT n√©cessite l'ajustement de ses param√®tres en fonction des donn√©es d'entr√©e, et il a utilis√© des milliards de donn√©es pour ajuster ses param√®tres.

- [01:11](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=71s) üìö Comment instruire ChatGPT ? : [Le LLM √† l'√©cole](https://github.com/jpbrasile/formationIA2.0/wiki/2.-LLM%E2%80%90Instruct) 
  - Pour instruire ChatGPT, il faut lui donner des directives sur son comportement.
  - Alimenter la machine avec une nouvelle base de donn√©es de type question-r√©ponse lui permet de mimer ce type de r√©sultat.
  - Des gardes-fous sont n√©cessaires pour censurer certaines r√©ponses et inculquer les bonnes mani√®res.

- [02:09](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=129s) üíª Implantation de ChatGPT

  - ChatGPT est principalement disponible en ligne via le Cloud, en raison de son co√ªt de d√©veloppement.
  - Le contr√¥le sur l'utilisation de ChatGPT est difficile, ce qui soul√®ve des pr√©occupations concernant la divulgation d'informations sensibles.
  - Un mouvement open source travaille sur des versions plus l√©g√®res de ChatGPT pour des utilisations locales.

- [03:18](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=198s) üß† La taille et le contexte des LLM : [Le LLM peut soutenir une conversation](https://github.com/jpbrasile/formationIA2.0/wiki/3.-LLM%E2%80%90Chat) 

  - Les LLM (Large Language Models) sont en constante √©volution pour devenir plus l√©gers tout en maintenant leur performance.
  - La taille des LLM est mesur√©e en milliards de bytes, et des versions plus compactes sont d√©velopp√©es.
  - Le contexte, ou m√©moire √† court terme, est crucial pour stocker des informations pertinentes lors de l'interaction avec un LLM.
 
  ## L'open-source proche de GPT4
  ![Capture d'√©cran 2024-01-24 155607](https://github.com/jpbrasile/formationIA2.0/assets/8331027/0ef1137e-e79c-405d-8816-cad6a82e41b6)

  ## Un stack local ou d√©ployable sur hostinger domaine: atthesametime.eu
  -  fait √† partir de [Colin](https://github.com/coleam00/local-ai-packaged)
  -  url:
      - n8N:    http://localhost:5678/
      - flowise: http://localhost:3001/
      - Searxng: http://localhost:8080/
      - openrouter: https://openrouter.ai/
      - openwebui: http://localhost:3000/
      - qdrant: http://localhost:6333/
      - caddy avec
          -  N8N_HOSTNAME=${N8N_HOSTNAME:-":8001"}
          - WEBUI_HOSTNAME=${WEBUI_HOSTNAME:-":8002"}
          - FLOWISE_HOSTNAME=${FLOWISE_HOSTNAME:-":8003"}
          - OLLAMA_HOSTNAME=${OLLAMA_HOSTNAME:-":8004"}
          - SUPABASE_HOSTNAME=${SUPABASE_HOSTNAME:-":8005"}
          - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-":8006"}
          - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL:-internal}
        - ollama: http://localhost:11434
- Hostinger : systeme d'exploitation avec docker (application)
 # Configuration compl√®te pour LocalAI Stack sur VM

## 1. Installation de Docker
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y git curl
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
# D√©connectez-vous et reconnectez-vous pour appliquer les changements
```

## 2. Configuration de la m√©moire swap
```bash
# Cr√©er un fichier swap de 8GB
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
# Rendre le swap permanent
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

## 3. Configuration du pare-feu UFW pour Docker
```bash
# Permettre le trafic sur l'interface docker0
sudo ufw allow in on docker0
sudo ufw allow out on docker0

# Permettre le trafic depuis le sous-r√©seau Docker
sudo ufw allow from 172.17.0.0/16
sudo ufw route allow in on docker0
sudo ufw route allow out on docker0

# Autoriser les ports n√©cessaires
sudo ufw allow 11434/tcp  # Pour Ollama
sudo ufw allow 3000/tcp   # Pour OpenWebUI
sudo ufw allow 3001/tcp   # Pour Flowise
sudo ufw allow 5678/tcp   # Pour n8n
sudo ufw allow 8080/tcp   # Pour SearxNG
sudo ufw allow 6333/tcp   # Pour Qdrant

# Recharger UFW
sudo ufw reload
```

## 4. Configuration de Docker Compose
Assurez-vous d'ajouter `extra_hosts` √† tous les services qui doivent communiquer avec d'autres services :

```yaml
services:
  votre-service:
    # ...autres configurations...
    extra_hosts:
      - "host.docker.internal:host-gateway"
```

Ou mieux, utilisez les noms de services directement (par exemple `http://ollama:11434`) puisque les conteneurs sont sur le m√™me r√©seau Docker.

## 5. Choix du mod√®le adapt√© aux ressources
Pour les VMs avec moins de 8GB de RAM :
```bash
docker exec -it ollama ollama pull phi3:mini
# ou
docker exec -it ollama ollama pull mistral:instruct
```

## Points importants √† retenir
- Le pare-feu UFW et Docker ont des interactions complexes qui n√©cessitent une configuration sp√©cifique
- Utilisez les noms de services pour la communication entre conteneurs sur le m√™me r√©seau
- Adaptez les mod√®les LLM √† vos ressources mat√©rielles disponibles
- V√©rifiez les connexions avec `curl` pour diagnostiquer les probl√®mes

Cette configuration devrait r√©soudre les probl√®mes de communication entre Docker et le syst√®me h√¥te, ainsi que les limitations de m√©moire pour les mod√®les LLM.


- http://host.docker.internal:11434/ --> ollama   // https://ollama.atthesametime.eu/
- http://host.docker.internal:6333/ -->  qdrant  //http://localhost:6333/  --> curl http://localhost:6333  dans hostinger
- https://searxng.atthesametime.eu/   http://localhost:8080/
- https://flowise.atthesametime.eu/   http://localhost:3001/
- https://supabase.atthesametime.eu/   http://localhost:5678/home/workflows
- https://openwebui.atthesametime.eu/      http://localhost:3000/
- https://n8n.atthesametime.eu/    http://localhost:5678/home/workflows

## IA Comment suivre le rythme ?
- Tout va tr√®s vite et pour ma^triser l'IA et ne pas √™tre seulement spectateur il faut une m√©thode, je propse le couper/coller
- Un acteur [Cole Melin](https://www.youtube.com/@ColeMedin) sur youtube, (cr√©ateur de bolt) travaille √† temps plein pour apporter sur la base de 2 vid√©os par semaine le r√©sultat de son travail. Il vise √† trouver des soutions g√©n√©ralements open source, et il est compl√®tement transparent sur ces propres travaux que l'on peut dupliquer .
- Ce travail de couper/coller demande n√©anmoins des efforts, mais c'est la meilleure fa√ßon d'apprendre √† apprendre , en √©tant acteur.
- J'ai ainsi dupliquer , temps en local que sur Hostinger avec mon domaine atthesametime.eu un stack qui correspond √† l'√©tat de l'art actuel avec
    - n8n : on peut automaiser pr√®s de 500 t√¢ches , elles sont accessibles via des nodes webhooks qui fournissent les url d'acc√®s et en cr√©ant les cr√©dentials requis
    - flowise: qui en nos code permet de cr√©er des agents
    - openwebui : qui permet d'interagir avec notre stack en no code aavec un interface rsssemblant √† celui de chatGPT
    - searxng pour les recherches sur le net
    - supabase et GDrant pour base de donn√©es
    - ollama pour les llm locaux.J'utilise aussi openrouter pour des llm plus performants (certains sont gratuits comme mistralai/mistral-small-3.1-24b-instruct:free 
    - caddy pour le cryptage
 
- Le portage sur Hostinger avec une configuration CPU 2 cores 8GB, 100GB ne co√ªte que ~ 6 ‚Ç¨ /mois et permet de partager le stack sur un r√©seau d√©localis√©    
-   
