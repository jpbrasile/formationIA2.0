# FormationIA2.0

<details>
<summary><b>Qu'est-ce que l'IA peut vous rapporter ?</b></summary>
<p>Ce document est intéressant car il explore l'impact réel des Modèles de Langage à Grande Échelle (LLM), comme GPT-4, sur des tâches complexes et riches en connaissances. L'étude, menée avec le Boston Consulting Group, impliquait 758 consultants et visait à comprendre comment l'IA peut améliorer la performance humaine dans un contexte professionnel.</p>
<p>Principales conclusions de l'étude :</p>
<ul>
    <li><strong>Productivité et Qualité Accrues</strong> : Les consultants utilisant l'IA étaient nettement plus productifs et produisaient un travail de meilleure qualité. En moyenne, ils ont complété 12,2 % de tâches en plus et ce, 25,1 % plus rapidement. De plus, la qualité de leur travail était supérieure de plus de 40 % par rapport à ceux n'utilisant pas l'IA.</li>
    <li><strong>Bénéfices à Tous les Niveaux de Compétences</strong> : L'étude a révélé que l'augmentation par l'IA profitait significativement aux consultants à tous les niveaux de compétence. Ceux en dessous du seuil de performance moyen ont vu leur performance augmenter de 43 %, tandis que ceux au-dessus ont amélioré de 17 %.</li>
    <li><strong>Limites de l'IA</strong> : L'étude a également identifié des tâches actuellement hors de portée de l'IA. Pour ces tâches, les consultants utilisant l'IA étaient 19 points de pourcentage moins susceptibles de produire des solutions correctes par rapport à ceux sans accès à l'IA.</li>
    <li><strong>Modèles d'Intégration de l'IA</strong> : L'étude a observé deux modèles distincts dans la façon dont les consultants intégraient l'IA dans leur travail :
        <ul>
            <li><strong>Centaures</strong> : Certains consultants agissaient comme des Centaures, divisant les tâches entre eux et l'IA, déléguant certaines activités à l'IA.</li>
            <li><strong>Cyborgs</strong> : D'autres agissaient plus comme des Cyborgs, intégrant complètement leur flux de travail avec l'IA et interagissant continuellement avec elle.</li>
        </ul>
    </li>
</ul>
<p>Pour plus de détails, consultez le document complet : <a href="https://www.hbs.edu/ris/Publication%20Files/24-013_d9b45b68-9e74-42d6-a1c6-c72fb70c7282.pdf">Lien vers l'étude</a>.</p>
</details>


<details>
  <summary> <b>Les astuces à utiliser</b></summary>
  <br> 
  <details>
    <summary> Impression d'écran sous windows?</summary>
   
    Touche Windows+MAj+S
  </details>
  <details>
    <summary> Insérer l'image dans GitHub</summary>

    Télécharger l'image puis simple upload au point de la page wiki où l'on veut mettre l'image
  </details>
  <details>
    <summary> Pour obtenir de chatGPT un format markdown à couper/coller </summary>
  
    "Fournis le contenu formaté en Markdown, présenté sous forme de chaîne de caractères " 
  </details>


   <details>
    <summary>accéder à toutes les commandes d'Harpa </summary>

   il suffit de mettre "/" dans le chat; ex: "/clear": supprime l'historique des chats.
  </details>
</details>
  
</details>


## Formation à l'IA en 2024: 

Dans le tableau ci-après: 3 niveaux de formation : Débutant, intermédiaire et avancé
- **Quels outils ?** : Ceux à maîtriser pour être efficace:  Halte aux problèmes ! Euh non !  "**Alt A <Problème>!**" et Harpa.ai vous répondra !
- **Le prompt** : Comment parler avec le chatbot pour que sa réponse soit pertinente ?
- **Fournir aux LLM nos propres données** : Comment le chatbot peut prendre en compte mes données ?
- **Accès à Internet**: Comment faire pour qu'il prenne les données pertinantes sur le cloud ?
- **Gérer le Contexte**: Comment composer avec sa mémoire vive qui ne peut accumuler qu'un nombre fini de données ?
- **Au delà de l'écrit** : Comment travailler avec des données non textuelles (images, son ... ) tant en entrée qu'en sortie ?
- **L'accès aux outils externes**: Comment faire que le chatbot accède à des ressources externes disponibles sur le web ?
- **Chatbots spécialisés** : Comment créer des chatbots spécialisés pour remplir certaines tâches ?
- **Travail en équipe**: Comment créer des chatbots travaillant en équipe
- **L'IA apprend toute seule** : Comment faire pour que les Chatbot apprennent de leurs erreurs ?

| Niveau        | Objectif                              | [Quels outils  ?](https://github.com/jpbrasile/formationIA2.0/wiki/Installation-des-outils.md)                           | [Le prompt](https://github.com/jpbrasile/formationIA2.0/wiki/4.-Le-prompting)                                           | [Fournir aux LLM nos propres données](https://github.com/jpbrasile/formationIA2.0/wiki/6.-Fournir-aux-LLM-nos-propres-donn%C3%A9es)                                               | [L'Accès à Internet](https://github.com/jpbrasile/formationIA2.0/wiki/L'acc%C3%A8s-%C3%A0-internet.md)                                            | [Gérer le contexte](https://github.com/jpbrasile/formationIA2.0/wiki/5.-Gestion-du-contexte)                                             | [Au delà de l'écrit](https://github.com/jpbrasile/formationIA2.0/wiki/9.-Les-LLM-multimodaux-(MLLM))                                         | [L'accès aux outils externes](https://github.com/jpbrasile/formationIA2.0/wiki/8.-L%E2%80%99Acc%C3%A8s-aux-API)                                               | [Chatbots spécialisés](https://github.com/jpbrasile/formationIA2.0/wiki/A.-Les-GPTs)                                              | [Travail en équipe](https://github.com/jpbrasile/formationIA2.0/wiki/B.-Les-agents)                                           | [L'IA apprend toute seule](https://github.com/jpbrasile/formationIA2.0/wiki/C.-L%E2%80%99apprentissage-par-renforcement-:)                                               |
|---------------|---------------------------------------|-----------------------------------------|------------------------------------------------------|------------------------------------------------------|-----------------------------------------------------|----------------------------------------------------|---------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|----------------------------------------------------|
| Débutant      | [Utiliser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/1-%20prendre%20des%20notes.md) [challenge](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/challenge.md)       | [Nos outils:](https://github.com/jpbrasile/formationIA2.0/wiki/01:-Comment-disposer-d'outils-qui-font-tout-pour-vous-%3F)  [ChatGPT](https://chat.openai.com/), [Copilot](https://copilot.microsoft.com/?culture=fr-fr&country=fr), [Harpa](https://harpa.ai/), [Perplexity](https://www.perplexity.ai/), [Canva](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/canva.md)           [ GitHub, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/github.md) [Capcut](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/capcut.md)  | [Les bases](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/3-%20le%20prompting.md) |Avec nos outils       | Avec nos outils              |  Un prompt pour demander la synthèse   | Copilot (dessin) et [outils en ligne, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/multimodal.md)| [Runway](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/Runway.md) [Outils en ligne](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20pour%20d%C3%A9butants/5-%20API.md)          |  |                |
| Intermédiaire | [Maîtriser l'IA, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)  [DeepLearning courses](https://www.deeplearning.ai/short-courses/)        | [Quel LLM ? ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhatLLM.md) [MixtralReplicate, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Replicate.md)    (MistralMédium](https://jeanviet.fr/mistral-medium/)        | [MetricMule et Formation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/le%20prompting.md)    |[Pinecone,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/RAG.md) [voiceflow,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)[Haystack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md) | [GPT Crawler,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/scraping.md) [GPT-Researcher, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPt-Researcher.md) [OnLine Shop](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/OnLineShop.md)                   | [MEMGPT,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/context.md)             | [ComfyUI,LLAVA,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/multimodal.md) [firellava](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/firellava.md) [Local ChatGPT, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Local%20ChatGPT.md) [WhisperSpeech, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/WhisperSpeech.md) [fuyu](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/fuyu.md)| [Langchain,...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/API.md) , [Colab, HF...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/choisir%20son%20IA.md)   ,[open interpreter](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Open%20Interpreter.md) [Phind, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Phind.md) [wolfram, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/programWithWolfram.md) [taskweaver, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/taskweaver.md) [AIDER, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/AIDER.md) [CURSOR](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/CURSOR.md)    | [emploi des GPTs openAI,](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/GPTs.md) [voiceflow](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/VoiceFlow.md)       |     [AutoGen, CrewAI, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/Agent.md) [n8n](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20interm%C3%A9diaire/n8n.md)       |   |
| Avancé        | [Créer avec l'IA](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/challenges.md),[aller plus loin](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Apprendre%20l'IA%20en%202024.md)       |[+vite](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Etat%20de%20l'art.md),[>GPT4](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Quel%20LLM.md) [Finetuning,Quantification...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/les%20outils.md) Création de MOE | [Prompt optimisé par programmation](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/prompting.md)                   | Création de base de données locales       | AgentSearch et Wiki search | Gestion avancée du contexte (compactage)                        | [animation 3D, audiobook...](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/multimodal.md) | Conception d'API robustes pour des applications à grande échelle | [Screen2Code, ](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/GPTs.md) [Crack](https://github.com/jpbrasile/formationIA2.0/blob/main/cours%20avanc%C3%A9/Crack.md)    | Développement d'agents autonomes capables d'apprentissage continu | Stratégies pour le développement de talents en IA et gestion des changements technologiques |

## ChatGPT C'est quoi ? : 
- [00:00](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=0s) 🤖 Qu'est-ce que ChatGPT ? [Large Language Model Base: un LLM à la maternelle](https://github.com/jpbrasile/formationIA2.0/wiki/1.-LLM%E2%80%90Base) 

  - ChatGPT est une machine à approximer qui fournit des réponses basées sur ce qu'il a appris.
  - Il est efficace pour interpoler mais peut fournir de fausses réponses en l'absence de données suffisantes.
  - L'apprentissage de ChatGPT nécessite l'ajustement de ses paramètres en fonction des données d'entrée, et il a utilisé des milliards de données pour ajuster ses paramètres.

- [01:11](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=71s) 📚 Comment instruire ChatGPT ? : [Le LLM à l'école](https://github.com/jpbrasile/formationIA2.0/wiki/2.-LLM%E2%80%90Instruct) 
  - Pour instruire ChatGPT, il faut lui donner des directives sur son comportement.
  - Alimenter la machine avec une nouvelle base de données de type question-réponse lui permet de mimer ce type de résultat.
  - Des gardes-fous sont nécessaires pour censurer certaines réponses et inculquer les bonnes manières.

- [02:09](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=129s) 💻 Implantation de ChatGPT

  - ChatGPT est principalement disponible en ligne via le Cloud, en raison de son coût de développement.
  - Le contrôle sur l'utilisation de ChatGPT est difficile, ce qui soulève des préoccupations concernant la divulgation d'informations sensibles.
  - Un mouvement open source travaille sur des versions plus légères de ChatGPT pour des utilisations locales.

- [03:18](https://www.youtube.com/watch?v=PNjh4z8WF9M&t=198s) 🧠 La taille et le contexte des LLM : [Le LLM peut soutenir une conversation](https://github.com/jpbrasile/formationIA2.0/wiki/3.-LLM%E2%80%90Chat) 

  - Les LLM (Large Language Models) sont en constante évolution pour devenir plus légers tout en maintenant leur performance.
  - La taille des LLM est mesurée en milliards de bytes, et des versions plus compactes sont développées.
  - Le contexte, ou mémoire à court terme, est crucial pour stocker des informations pertinentes lors de l'interaction avec un LLM.
 
  ## L'open-source proche de GPT4
  ![Capture d'écran 2024-01-24 155607](https://github.com/jpbrasile/formationIA2.0/assets/8331027/0ef1137e-e79c-405d-8816-cad6a82e41b6)

  ## Un stack local ou déployable sur hostinger domaine: atthesametime.eu
  -  fait à partir de [Colin](https://github.com/coleam00/local-ai-packaged)
  -  url:
      - n8N:    http://localhost:5678/
      - flowise: http://localhost:3001/
      - Searxng: http://localhost:8080/
      - openrouter: https://openrouter.ai/
      - openwebui: http://localhost:3000/
      - qdrant: http://localhost:6333/
      - caddy avec
          -  N8N_HOSTNAME=${N8N_HOSTNAME:-":8001"}
          - WEBUI_HOSTNAME=${WEBUI_HOSTNAME:-":8002"}
          - FLOWISE_HOSTNAME=${FLOWISE_HOSTNAME:-":8003"}
          - OLLAMA_HOSTNAME=${OLLAMA_HOSTNAME:-":8004"}
          - SUPABASE_HOSTNAME=${SUPABASE_HOSTNAME:-":8005"}
          - SEARXNG_HOSTNAME=${SEARXNG_HOSTNAME:-":8006"}
          - LETSENCRYPT_EMAIL=${LETSENCRYPT_EMAIL:-internal}
        - ollama: http://localhost:11434
- Hostinger : systeme d'exploitation avec docker (application)
 # Configuration complète pour LocalAI Stack sur VM

## 1. Installation de Docker
```bash
sudo apt update && sudo apt upgrade -y
sudo apt install -y git curl
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER
# Déconnectez-vous et reconnectez-vous pour appliquer les changements
```

## 2. Configuration de la mémoire swap
```bash
# Créer un fichier swap de 8GB
sudo fallocate -l 8G /swapfile
sudo chmod 600 /swapfile
sudo mkswap /swapfile
sudo swapon /swapfile
# Rendre le swap permanent
echo '/swapfile none swap sw 0 0' | sudo tee -a /etc/fstab
```

## 3. Configuration du pare-feu UFW pour Docker
```bash
# Permettre le trafic sur l'interface docker0
sudo ufw allow in on docker0
sudo ufw allow out on docker0

# Permettre le trafic depuis le sous-réseau Docker
sudo ufw allow from 172.17.0.0/16
sudo ufw route allow in on docker0
sudo ufw route allow out on docker0

# Autoriser les ports nécessaires
sudo ufw allow 11434/tcp  # Pour Ollama
sudo ufw allow 3000/tcp   # Pour OpenWebUI
sudo ufw allow 3001/tcp   # Pour Flowise
sudo ufw allow 5678/tcp   # Pour n8n
sudo ufw allow 8080/tcp   # Pour SearxNG
sudo ufw allow 6333/tcp   # Pour Qdrant

# Recharger UFW
sudo ufw reload
```

## 4. Configuration de Docker Compose
Assurez-vous d'ajouter `extra_hosts` à tous les services qui doivent communiquer avec d'autres services :

```yaml
services:
  votre-service:
    # ...autres configurations...
    extra_hosts:
      - "host.docker.internal:host-gateway"
```

Ou mieux, utilisez les noms de services directement (par exemple `http://ollama:11434`) puisque les conteneurs sont sur le même réseau Docker.

## 5. Choix du modèle adapté aux ressources
Pour les VMs avec moins de 8GB de RAM :
```bash
docker exec -it ollama ollama pull phi3:mini
# ou
docker exec -it ollama ollama pull mistral:instruct
```

## Points importants à retenir
- Le pare-feu UFW et Docker ont des interactions complexes qui nécessitent une configuration spécifique
- Utilisez les noms de services pour la communication entre conteneurs sur le même réseau
- Adaptez les modèles LLM à vos ressources matérielles disponibles
- Vérifiez les connexions avec `curl` pour diagnostiquer les problèmes

Cette configuration devrait résoudre les problèmes de communication entre Docker et le système hôte, ainsi que les limitations de mémoire pour les modèles LLM.


- http://host.docker.internal:11434/ --> ollama   // https://ollama.atthesametime.eu/
- http://host.docker.internal:6333/ -->  qdrant  //http://localhost:6333/  --> curl http://localhost:6333  dans hostinger
- https://searxng.atthesametime.eu/   http://localhost:8080/
- https://flowise.atthesametime.eu/   http://localhost:3001/
- https://supabase.atthesametime.eu/   http://localhost:5678/home/workflows
- https://openwebui.atthesametime.eu/      http://localhost:3000/
- https://n8n.atthesametime.eu/    http://localhost:5678/home/workflows

## IA Comment suivre le rythme ?
- Tout va très vite et pour ma^triser l'IA et ne pas être seulement spectateur il faut une méthode, je propse le couper/coller
- Un acteur [Cole Melin](https://www.youtube.com/@ColeMedin) sur youtube, (créateur de bolt) travaille à temps plein pour apporter sur la base de 2 vidéos par semaine le résultat de son travail. Il vise à trouver des soutions généralements open source, et il est complètement transparent sur ces propres travaux que l'on peut dupliquer .
- Ce travail de couper/coller demande néanmoins des efforts, mais c'est la meilleure façon d'apprendre à apprendre , en étant acteur.
- J'ai ainsi dupliquer , temps en local que sur Hostinger avec mon domaine atthesametime.eu un stack qui correspond à l'état de l'art actuel avec
    - n8n : on peut automaiser près de 500 tâches , elles sont accessibles via des nodes webhooks qui fournissent les url d'accès et en créant les crédentials requis
    - flowise: qui en nos code permet de créer des agents
    - openwebui : qui permet d'interagir avec notre stack en no code aavec un interface rsssemblant à celui de chatGPT
    - searxng pour les recherches sur le net
    - supabase et GDrant pour base de données
    - ollama pour les llm locaux.J'utilise aussi openrouter pour des llm plus performants (certains sont gratuits comme mistralai/mistral-small-3.1-24b-instruct:free 
    - caddy pour le cryptage
 
- Le portage sur Hostinger avec une configuration CPU 2 cores 8GB, 100GB ne coûte que ~ 6 € /mois et permet de partager le stack sur un réseau délocalisé    
-   
