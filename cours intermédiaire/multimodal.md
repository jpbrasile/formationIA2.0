## ComfyUI
### Stable Diffusion Animation
- [00:00](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=0s) ðŸ“¹ Le tutoriel explique comment utiliser Stable Diffusion Animation pour changer facilement les arriÃ¨re-plans et les tenues des personnages dans une animation.
- [00:13](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=13s) ðŸ¤– L'animateur a amÃ©liorÃ© son flux de travail d'animation grÃ¢ce aux suggestions de ses amis IA, rendant le processus plus fluide.
- [01:23](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=83s) ðŸ“Š Le tutoriel montre un nouveau design de mise en page et l'utilisation de nÅ“uds personnalisÃ©s pour la distribution de donnÃ©es.
- [03:12](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=192s) ðŸŽ­ Le flux de travail est organisÃ© en groupes dÃ©diÃ©s Ã  des tÃ¢ches spÃ©cifiques, tels que l'Ã©change de visages ou la segmentation d'image.
- [19:07](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=1147s) ðŸŒ„ L'ajout d'adaptateurs d'image influence fortement les rÃ©sultats de l'animation, permettant de contrÃ´ler les arriÃ¨re-plans et les tenues des personnages.
### Tuto 3
- [00:00](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=0s) ðŸ“Œ Un "latent image" en IA ne contient pas d'image rÃ©elle, mais plutÃ´t des points latents.
- [01:27](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=87s) ðŸ“Š Le workflow de base pour crÃ©er une image Ã  partir de texte comprend un checkpoint, des prompts textuels, une image latente vide et un VAE.
- [02:34](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=154s) ðŸ–¼ï¸ Pour des images de plus haute rÃ©solution, il est nÃ©cessaire d'effectuer une mise Ã  l'Ã©chelle (upscale) de l'image latente.
- [03:17](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=197s) ðŸ› ï¸ Vous pouvez dÃ©sactiver des parties de votre workflow pour Ã©conomiser du temps et de la puissance GPU.
- [05:31](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=331s) ðŸ–¼ï¸ L'Ã©tape d'upscale latent permet d'augmenter la taille de l'image en multipliant la largeur et la hauteur.
- [06:23](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=383s) ðŸŽ¨ Vous pouvez influencer le rÃ©sultat de l'upscale en ajustant les prompts textuels et en utilisant diffÃ©rents samplers.
- [07:03](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=423s) ðŸ§¹ Un dÃ©bruitage Ã©levÃ© est recommandÃ© pour les images upscale latentes pour Ã©liminer le bruit.
- [08:10](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=490s) âœ‚ï¸ L'upscale latent peut amÃ©liorer la qualitÃ© et la prÃ©cision de l'image avant d'utiliser l'ultimate upscaler pour une taille encore plus grande.
- [**Le Workflow**](https://openart.ai/workflows/oliviosarikas/lesson-3---comfy-academy/8n40kHT7p1krLwCdihdY)


## Un OCR multilingue en [colab notebook](https://colab.research.google.com/drive/17NBCTfYXp3Dr-3lXf_IHCKaCl9FgpNy_?usp=sharing)
- Ces [performances](https://github.com/VikParuchuri/surya?tab=readme-ov-file#benchmarks)
- 
## [Apprendre Python](https://learnpythonfast.up.railway.app/) : une application texte et voix

## [DÃ©tection d'objets en temps rÃ©el](https://github.com/Deci-AI/super-gradients?tab=readme-ov-file#implemented-model-architectures):

- La page prÃ©sente le projet open source Deci-AI/super-gradients.
- La bibliothÃ¨que est sous licence Apache-2.0.
- Elle offre des fonctionnalitÃ©s pour former et affiner des modÃ¨les de vision par ordinateur.
- Elle met en avant les architectures YOLO-NAS et YOLO-NAS-POSE pour des performances de pointe en termes de prÃ©cision et de vitesse.
- **Elle propose des modÃ¨les prÃ©-entraÃ®nÃ©s pour la classification, la segmentation sÃ©mantique, la dÃ©tection d'objets et l'estimation de la pose.Notebook colab disponibles**
- Elle facilite l'intÃ©gration des modÃ¨les dans des outils de dÃ©ploiement tels que TensorRT et OpenVINO.
- Des exemples de code sont fournis pour l'utilisation de la bibliothÃ¨que.
- La page contient des informations sur les versions rÃ©centes de la bibliothÃ¨que, des tutoriels et des informations sur l'installation.
- Elle mentionne Ã©galement des architectures de modÃ¨les prises en charge, des ensembles de donnÃ©es implÃ©mentÃ©s, de la documentation, et la possibilitÃ© de contribuer au projet.
- Enfin, la page prÃ©sente la licence Apache 2.0 et des informations sur la plateforme Deci pour le dÃ©ploiement de modÃ¨les d'apprentissage profond.

## Transcript en temps rÃ©el
- [00:00](https://youtu.be/k6nIxWGdrS4?t=0s) ðŸŽ™ï¸ CrÃ©ation d'une transcription en temps rÃ©el Ã  quasi-zÃ©ro latence.
- [00:27](https://youtu.be/k6nIxWGdrS4?t=27s) ðŸš€ Utilisation de Fast Whisperer pour une transcription rapide en temps rÃ©el.
- [01:36](https://youtu.be/k6nIxWGdrS4?t=96s) ðŸ’» Configuration facile en utilisant Python et Whisper, avec des options de modÃ¨le et de langue.
- [03:39](https://youtu.be/k6nIxWGdrS4?t=219s) ðŸ˜„ Application de l'analyse de sentiment en temps rÃ©el avec GPT-4 pour des rÃ©ponses positives, nÃ©gatives ou neutres.
- [05:57](https://youtu.be/k6nIxWGdrS4?t=357s) ðŸ“¸ PrÃ©visualisation de la crÃ©ation d'images en temps rÃ©el Ã  partir de descriptions, utilisant Fast Whisperer et d'autres techniques.
## [Transcription voix (en anglais) -> texte avec parakeet](https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b)
