## [Ctrl C ctrl V !](https://openart.ai/workflows/home?appSort=featured) 
![Capture d'Ã©cran 2024-01-22 092344](https://github.com/jpbrasile/formationIA2.0/assets/8331027/674dc59e-bdcf-41cf-9065-d55c5c894a72)

## Transforme ta video en un avatar animÃ© !
The [video](https://www.youtube.com/watch?v=mHDRDHQjVlo&t=22s) is a  tutorial on using a complex AI-driven workflow for creating stable, high-quality AI-generated videos, specifically focusing on the utilization of stable diffusion and DV (Deep Vision) POS (Pose Estimation) inputs.
## ComfyUI
### Stable Diffusion Animation
- [00:00](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=0s) ðŸ“¹ Le tutoriel explique comment utiliser Stable Diffusion Animation pour changer facilement les arriÃ¨re-plans et les tenues des personnages dans une animation.
- [00:13](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=13s) ðŸ¤– L'animateur a amÃ©liorÃ© son flux de travail d'animation grÃ¢ce aux suggestions de ses amis IA, rendant le processus plus fluide.
- [01:23](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=83s) ðŸ“Š Le tutoriel montre un nouveau design de mise en page et l'utilisation de nÅ“uds personnalisÃ©s pour la distribution de donnÃ©es.
- [03:12](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=192s) ðŸŽ­ Le flux de travail est organisÃ© en groupes dÃ©diÃ©s Ã  des tÃ¢ches spÃ©cifiques, tels que l'Ã©change de visages ou la segmentation d'image.
- [19:07](https://www.youtube.com/watch?v=Sg3KgA3_fPU&t=1147s) ðŸŒ„ L'ajout d'adaptateurs d'image influence fortement les rÃ©sultats de l'animation, permettant de contrÃ´ler les arriÃ¨re-plans et les tenues des personnages.
### Tuto 3
- [00:00](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=0s) ðŸ“Œ Un "latent image" en IA ne contient pas d'image rÃ©elle, mais plutÃ´t des points latents.
- [01:27](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=87s) ðŸ“Š Le workflow de base pour crÃ©er une image Ã  partir de texte comprend un checkpoint, des prompts textuels, une image latente vide et un VAE.
- [02:34](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=154s) ðŸ–¼ï¸ Pour des images de plus haute rÃ©solution, il est nÃ©cessaire d'effectuer une mise Ã  l'Ã©chelle (upscale) de l'image latente.
- [03:17](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=197s) ðŸ› ï¸ Vous pouvez dÃ©sactiver des parties de votre workflow pour Ã©conomiser du temps et de la puissance GPU.
- [05:31](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=331s) ðŸ–¼ï¸ L'Ã©tape d'upscale latent permet d'augmenter la taille de l'image en multipliant la largeur et la hauteur.
- [06:23](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=383s) ðŸŽ¨ Vous pouvez influencer le rÃ©sultat de l'upscale en ajustant les prompts textuels et en utilisant diffÃ©rents samplers.
- [07:03](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=423s) ðŸ§¹ Un dÃ©bruitage Ã©levÃ© est recommandÃ© pour les images upscale latentes pour Ã©liminer le bruit.
- [08:10](https://www.youtube.com/watch?v=3W-_B_0F7-g&t=490s) âœ‚ï¸ L'upscale latent peut amÃ©liorer la qualitÃ© et la prÃ©cision de l'image avant d'utiliser l'ultimate upscaler pour une taille encore plus grande.
- [**Le Workflow**](https://openart.ai/workflows/oliviosarikas/lesson-3---comfy-academy/8n40kHT7p1krLwCdihdY)

## Tuto 4 :[Img2Img Painting in ComfyUI - Comfy Academy](https://www.youtube.com/watch?v=179OUihyihk)
https://openart.ai/workflows/oliviosarikas/lesson-4---comfy-academy/33ECh584TbdXjPyitkff

La vidÃ©o de Comfy Academy, intitulÃ©e "Img2Img Painting in ComfyUI", est une prÃ©sentation dÃ©taillÃ©e sur l'utilisation de l'intelligence artificielle (IA) pour la crÃ©ation d'images Ã  partir d'autres images. Le formateur commence par expliquer comment tÃ©lÃ©charger et utiliser son flux de travail sur Open Art, en mettant l'accent sur l'aspect pratique de son atelier accessible dans le cloud sans installation nÃ©cessaire.

Le cÅ“ur de la vidÃ©o se concentre sur l'explication de son flux de travail pour transformer une image en pixels en une image latente Ã  l'aide de l'encodage VAE. Cette technique permet de transformer de simples dessins en Å“uvres d'art complexes, en dÃ©finissant les couleurs, la composition, et en pensant comme un artiste. L'intervenant souligne que mÃªme les dessins rudimentaires peuvent Ãªtre utilisÃ©s pour guider l'IA dans la crÃ©ation d'images dÃ©taillÃ©es.

L'exemple utilisÃ© pour illustrer ce processus est un dessin simpliste d'un ange avec des ailes, oÃ¹ l'intervenant montre comment varier les dÃ©tails du dessin, comme la texture des ailes, pour obtenir des rÃ©sultats diffÃ©rents. Il met en lumiÃ¨re l'importance du rÃ©glage du niveau de dÃ©bruitage (D noise) pour contrÃ´ler la libertÃ© donnÃ©e Ã  l'IA dans l'interprÃ©tation de l'image.

La vidÃ©o prÃ©sente Ã©galement des exemples de rendus basÃ©s sur des dessins et des prompts textuels variÃ©s, montrant l'effet des modifications apportÃ©es sur les rÃ©sultats finaux. L'intervenant encourage Ã  expÃ©rimenter avec diffÃ©rents dessins et paramÃ¨tres pour explorer les capacitÃ©s crÃ©atives de l'outil.

Ensuite, il introduit une technique alternative utilisant des gradients comme entrÃ©es d'image, expliquant comment cela peut influencer la tempÃ©rature de couleur et l'ambiance des images gÃ©nÃ©rÃ©es. L'utilisation de mÃ©langes de latents et d'autres techniques permet de manipuler davantage les rÃ©sultats.

En conclusion, la vidÃ©o met en Ã©vidence la puissance et la flexibilitÃ© de l'utilisation de l'IA pour la crÃ©ation artistique, en offrant des contrÃ´les crÃ©atifs Ã©tendus au-delÃ  des capacitÃ©s de modÃ¨les standard. L'intervenant termine en anticipant un prochain tutoriel sur l'utilisation des entrÃ©es d'images latentes pour des crÃ©ations plus avancÃ©es, et encourage les spectateurs Ã  expÃ©rimenter avec les techniques prÃ©sentÃ©es.

## Un OCR multilingue en [colab notebook](https://colab.research.google.com/drive/17NBCTfYXp3Dr-3lXf_IHCKaCl9FgpNy_?usp=sharing)
- Ces [performances](https://github.com/VikParuchuri/surya?tab=readme-ov-file#benchmarks)
- 
## [Apprendre Python](https://learnpythonfast.up.railway.app/) : une application texte et voix

## [DÃ©tection d'objets en temps rÃ©el](https://github.com/Deci-AI/super-gradients?tab=readme-ov-file#implemented-model-architectures):

- La page prÃ©sente le projet open source Deci-AI/super-gradients.
- La bibliothÃ¨que est sous licence Apache-2.0.
- Elle offre des fonctionnalitÃ©s pour former et affiner des modÃ¨les de vision par ordinateur.
- Elle met en avant les architectures YOLO-NAS et YOLO-NAS-POSE pour des performances de pointe en termes de prÃ©cision et de vitesse.
- **Elle propose des modÃ¨les prÃ©-entraÃ®nÃ©s pour la classification, la segmentation sÃ©mantique, la dÃ©tection d'objets et l'estimation de la pose.Notebook colab disponibles**
- Elle facilite l'intÃ©gration des modÃ¨les dans des outils de dÃ©ploiement tels que TensorRT et OpenVINO.
- Des exemples de code sont fournis pour l'utilisation de la bibliothÃ¨que.
- La page contient des informations sur les versions rÃ©centes de la bibliothÃ¨que, des tutoriels et des informations sur l'installation.
- Elle mentionne Ã©galement des architectures de modÃ¨les prises en charge, des ensembles de donnÃ©es implÃ©mentÃ©s, de la documentation, et la possibilitÃ© de contribuer au projet.
- Enfin, la page prÃ©sente la licence Apache 2.0 et des informations sur la plateforme Deci pour le dÃ©ploiement de modÃ¨les d'apprentissage profond.

## Transcript en temps rÃ©el
- [00:00](https://youtu.be/k6nIxWGdrS4?t=0s) ðŸŽ™ï¸ CrÃ©ation d'une transcription en temps rÃ©el Ã  quasi-zÃ©ro latence.
- [00:27](https://youtu.be/k6nIxWGdrS4?t=27s) ðŸš€ Utilisation de Fast Whisperer pour une transcription rapide en temps rÃ©el.
- [01:36](https://youtu.be/k6nIxWGdrS4?t=96s) ðŸ’» Configuration facile en utilisant Python et Whisper, avec des options de modÃ¨le et de langue.
- [03:39](https://youtu.be/k6nIxWGdrS4?t=219s) ðŸ˜„ Application de l'analyse de sentiment en temps rÃ©el avec GPT-4 pour des rÃ©ponses positives, nÃ©gatives ou neutres.
- [05:57](https://youtu.be/k6nIxWGdrS4?t=357s) ðŸ“¸ PrÃ©visualisation de la crÃ©ation d'images en temps rÃ©el Ã  partir de descriptions, utilisant Fast Whisperer et d'autres techniques.
## [Transcription voix (en anglais) -> texte avec parakeet](https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b)
- Meilleur que Whisper sur ce [leader board](https://huggingface.co/spaces/hf-audio/open_asr_leaderboard)
