### Conclusion Principale
La conclusion principale de la [page](https://app.fireworks.ai/blog/firellava-the-first-commercially-permissive-oss-llava-model) est que Fireworks.ai a open-sourcé le modèle FireLLaVA sous la licence communautaire Llama 2, ce qui en fait le premier modèle multi-modal LLaVA avec une licence commercialement permissive.

### Résumé
- Fireworks.ai a open-sourcé le modèle FireLLaVA sous la licence Llama 2 Community License.
- Il s'agit du premier modèle multi-modal LLaVA avec une licence commercialement permissive.
- On peut télécharger FireLLaVA depuis leur référentiel Huggingface, l'utiliser via leur API rapide ou l'expérimenter dans leur playground.
- Les modèles Vision-Language (VLMs) comprennent à la fois le contenu visuel et les indications textuelles.
- LLaVA est un modèle de langage visuel (VLM) développé par Haotian Liu et al, qui obtient de bonnes performances sur 11 benchmarks.
- FireLLaVA a été formé avec une seule image dans la conversation, ce qui peut affecter ses performances lorsque plusieurs images sont présentes.
- Il est recommandé d'inclure uniquement la dernière image dans la conversation lors de l'utilisation du modèle FireLLaVA pour construire un chatbot capable de vision.
- Fireworks.ai a utilisé une approche novatrice pour former FireLLaVA en utilisant le modèle CodeLlama 34B Instruct pour générer des conversations de langage visuel.
- Le modèle FireLLaVA répond bien aux instructions claires et à la compréhension visuelle de contenu abstrait.
- Il est compatible avec les API de complétion et de chat complétion de OpenAI Vision models.
- FireLLaVA performe presque aussi bien que le modèle LLaVA original sur quatre des sept benchmarks testés.
- L'utilisation de modèles Language-Only pour générer des données de formation de haute qualité pour les modèles VLM est avantageuse.
- Des API sont disponibles pour intégrer les capacités de vision dans les applications grâce au modèle LLaVA.

Cela résume les principaux points de la page web.
