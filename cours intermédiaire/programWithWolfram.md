### Principale conclusion
La principale conclusion de la [page web](https://community.wolfram.com/groups/-/m/t/3097299) est que l'utilisation de modèles de langage de grande taille (LLMs) pour la programmation dans le langage Wolfram offre une efficacité accrue et une manière nouvelle de résoudre des problèmes.

### Résumé
- L'auteur, Marco Thiel de l'Université d'Aberdeen, utilise le langage Wolfram depuis de nombreuses années pour l'enseignement et la recherche académique et industrielle.
- Il souligne l'efficacité du langage Wolfram en raison de sa riche vocabulaire, de ses fonctions bien conçues, de ses données intégrées et de ses options d'utilisation de HPCs et de GPUs.
- L'auteur mentionne l'ajout de nouvelles fonctions telles que LLMSynthesize et LLMFunction pour accéder aux derniers modèles d'OpenAI, tels que GPT-4, DALLE, TTS, etc., ce qui a changé sa façon de programmer.
- L'auteur décrit comment il utilise GPT pour générer du code, interpréter des données et générer des idées de recherche.
- Il explique comment utiliser des LLMs gratuitement en les exécutant localement sur son ordinateur avec un contrôle total.
- L'auteur mentionne que l'accès aux LLMs via l'API OpenAI nécessite un compte payant, mais il explore des alternatives gratuites telles qu'Ollama.ai, qui permettent d'installer localement plusieurs LLMs.
- Il répertorie différents modèles LLM disponibles sur Ollama.ai, tels que Llama2, Mistral, Starling-LM, Codellama, et d'autres, et souligne leur utilité pour différentes tâches de programmation.
- L'auteur conclut en soulignant que l'utilisation de LLMs a amélioré son efficacité de travail et espère que de telles fonctionnalités seront disponibles pour tous les utilisateurs du langage Wolfram à l'avenir.
