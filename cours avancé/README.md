### RÃ©sumÃ© ClÃ©
L'[article](https://towardsdatascience.com/solving-reasoning-problems-with-llms-in-2023-6643bdfd606d#1acd) souligne l'Ã©volution importante des modÃ¨les de langage Ã  grande Ã©chelle (LLM) en 2023, notamment dans la rÃ©solution de problÃ¨mes de raisonnement et l'utilisation d'outils. Il met en Ã©vidence les progrÃ¨s dans l'utilisation d'outils externes et les capacitÃ©s de raisonnement interne des LLM, ainsi que l'exploration de nouvelles mÃ©thodes pour amÃ©liorer ces capacitÃ©s.

### RÃ©sumÃ©
- **Introduction et Contexte**
  - ChatGPT a fÃªtÃ© son premier anniversaire en 2024.
  - L'annÃ©e 2023 a Ã©tÃ© marquÃ©e par de nombreux dÃ©veloppements dans le domaine des LLM.

- **Utilisation des Outils**
  - Les LLM ont Ã©tÃ© Ã©quipÃ©s d'outils externes tels que les moteurs de recherche et les interprÃ©teurs de code.
  - La mÃ©thode d'apprentissage en contexte permet une utilisation plus efficace des outils.
  - L'article aborde des projets spÃ©cifiques comme Toolformer, Chameleon, et ToolkenGPT.

- **Raisonnement**
  - Accent sur la rÃ©solution de problÃ¨mes complexes via les capacitÃ©s de raisonnement internes des LLM.
  - Exploration des limites et des moyens d'Ã©tendre les capacitÃ©s de raisonnement des LLM.

- **CrÃ©ation de Propres Outils par les LLM**
  - Des travaux prÃ©liminaires ont explorÃ© la capacitÃ© des LLM Ã  crÃ©er des outils, en particulier des fonctions Python et des rÃ¨gles textuelles.

- **Planification et SÃ©ries Auto**
  - Les mÃ©thodes comme le raisonnement via la planification et les sÃ©ries auto dÃ©montrent des avancÃ©es dans le raisonnement plus complexe et l'auto-amÃ©lioration des LLM.

- **Observations et Ã‰valuations**
  - Des Ã©tudes ont Ã©tÃ© menÃ©es sur la capacitÃ© de mÃ©morisation des LLM et leur tendance Ã  mÃ©moriser des solutions plutÃ´t qu'Ã  raisonner de maniÃ¨re autonome.

- **PrÃ©visions pour 2024**
  - PrÃ©dictions sur l'Ã©volution future des LLM, incluant l'intÃ©gration multimodale et une meilleure comprÃ©hension du processus de raisonnement.

- **Divers**
  - L'article mentionne Ã©galement des travaux connexes et des blogs sur le raisonnement des LLM.

- **Conclusion**
  - L'annÃ©e 2023 a Ã©tÃ© significative pour le dÃ©veloppement et l'utilisation des LLM dans la rÃ©solution de problÃ¨mes de raisonnement et l'utilisation d'outils, posant des bases pour de futures avancÃ©es dans ce domaine.
 

#### In-context learning :
- [Toolformer](https://arxiv.org/abs/2302.04761):
    - ğŸ¤– Les modÃ¨les de langage (LMs) peuvent apprendre Ã  utiliser des outils externes via des APIs simples.
    - ğŸ“š Toolformer est un modÃ¨le formÃ© pour dÃ©cider quelles APIs appeler, quand les appeler, quels arguments passer, et comment incorporer les rÃ©sultats dans les prÃ©dictions futures de tokens.
    - ğŸ’¡ Cette formation est rÃ©alisÃ©e de maniÃ¨re auto-supervisÃ©e, nÃ©cessitant seulement quelques dÃ©monstrations pour chaque API.
    - ğŸ§® Toolformer intÃ¨gre divers outils tels qu'une calculatrice, un systÃ¨me de questions-rÃ©ponses, deux moteurs de recherche diffÃ©rents, un systÃ¨me de traduction et un calendrier.
    - ğŸš€ Toolformer amÃ©liore considÃ©rablement les performances en zÃ©ro-shot dans diverses tÃ¢ches, souvent compÃ©titives avec des modÃ¨les beaucoup plus grands, sans sacrifier ses capacitÃ©s de modÃ©lisation linguistique de base.
- [Chameleon](https://arxiv.org/abs/2304.09842):
  - ğŸ§© Les grands modÃ¨les de langage (LLM) ont des capacitÃ©s de raisonnement Ã©mergentes, mais prÃ©sentent des limites telles que l'incapacitÃ© d'accÃ©der Ã  des informations rÃ©centes sur le Web ou des bases de connaissances spÃ©cifiques aux tÃ¢ches, l'utilisation d'outils externes, et la rÃ©alisation de raisonnements mathÃ©matiques et logiques prÃ©cis.
  - ğŸŒ Chameleon est un systÃ¨me d'IA qui comble ces limites en ajoutant des modules plug-and-play aux LLM pour le raisonnement compositionnel. Il synthÃ©tise des programmes en combinant divers outils tels que les LLM, les modÃ¨les de vision prÃ©fabriquÃ©s, les moteurs de recherche Web, les fonctions Python et des modules basÃ©s sur des heuristiques pour accomplir des tÃ¢ches de raisonnement complexes.
  - ğŸ“Š Au cÅ“ur de Chameleon se trouve un planificateur basÃ© sur un LLM qui assemble une sÃ©quence d'outils pour gÃ©nÃ©rer la rÃ©ponse finale.
  - ğŸ“ˆ Chameleon, alimentÃ© par GPT-4, amÃ©liore considÃ©rablement les performances sur les tÃ¢ches de raisonnement intensif en connaissances multimodales, atteignant une prÃ©cision globale de 86,54% sur ScienceQA et 98,78% sur TabMWP.
  - ğŸ§  L'analyse montre que le planificateur alimentÃ© par GPT-4 sÃ©lectionne de maniÃ¨re plus cohÃ©rente et rationnelle les outils en dÃ©duisant des contraintes potentielles Ã  partir des instructions, par rapport Ã  un planificateur alimentÃ© par ChatGPT.
- [Visual reasoning](https://arxiv.org/abs/2211.11559)
  - ğŸ§  VISPROG est une approche neuro-symbolique pour rÃ©soudre des tÃ¢ches visuelles complexes et compositionnelles avec des instructions en langage naturel.
  - ğŸ“œ VISPROG gÃ©nÃ¨re des programmes modulaires de type Python sans nÃ©cessiter d'entraÃ®nement spÃ©cifique Ã  la tÃ¢che.
  - ğŸ–¼ï¸ Ces programmes peuvent utiliser diffÃ©rents modÃ¨les de vision par ordinateur, des routines de traitement d'image ou des fonctions Python pour produire des sorties intermÃ©diaires.
  - ğŸ’¡ Il peut Ãªtre utilisÃ© pour des tÃ¢ches telles que la rÃ©ponse Ã  des questions visuelles compositionnelles, le raisonnement sur des paires d'images, l'Ã©tiquetage d'objets de connaissances factuelles et la modification d'images guidÃ©e par le langage.
  - ğŸŒ VISPROG Ã©tend la portÃ©e des systÃ¨mes d'IA pour rÃ©soudre des tÃ¢ches complexes sans nÃ©cessiter un apprentissage spÃ©cifique Ã  la tÃ¢che.
- [ToolkenGPT](https://arxiv.org/abs/2305.11554):
  - ğŸ’¡ Les auteurs reconnaissent le soutien de la Fondation Simons et des contributeurs.
  - ğŸ’¡ L'article prÃ©sente ToolkenGPT, une approche pour amÃ©liorer les modÃ¨les de langage avec des outils externes.
  - ğŸ’¡ Les mÃ©thodes traditionnelles de finetuning des modÃ¨les de langage avec des donnÃ©es de dÃ©monstration d'outils peuvent Ãªtre coÃ»teuses et limitÃ©es Ã  un ensemble prÃ©dÃ©fini d'outils.
  - ğŸ’¡ ToolkenGPT combine les avantages des mÃ©thodes traditionnelles et de l'apprentissage en contexte pour augmenter les modÃ¨les de langage.
  - ğŸ’¡ Il permet d'ajouter un nombre arbitraire d'outils en temps rÃ©el et d'amÃ©liorer leur utilisation grÃ¢ce Ã  des donnÃ©es de dÃ©monstration.
  - ğŸ’¡ L'approche est efficace dans divers domaines, tels que la rÃ©solution de problÃ¨mes numÃ©riques, la rÃ©ponse aux questions basÃ©es sur la connaissance et la gÃ©nÃ©ration de plans incarnÃ©s.
  - ğŸ’¡ ToolkenGPT montre la capacitÃ© prometteuse d'utiliser des outils pertinents Ã  partir d'un grand ensemble d'outils dans des scÃ©narios complexes.
#### Most used tools: code interpreters and retrievers
- [COT](https://arxiv.org/abs/2201.11903):
  - ğŸ§  La gÃ©nÃ©ration d'une chaÃ®ne de pensÃ©e amÃ©liore les capacitÃ©s de raisonnement des grands modÃ¨les de langage.
  - ğŸ“š Cette amÃ©lioration rÃ©sulte de la mÃ©thode de chaÃ®ne de pensÃ©e, qui utilise des exemples de dÃ©monstrations de chaÃ®ne de pensÃ©e.
  - ğŸ§® Les expÃ©riences montrent que cette mÃ©thode amÃ©liore les performances dans des tÃ¢ches de raisonnement arithmÃ©tique, de bon sens et symbolique.
  - ğŸ“ˆ L'amÃ©lioration est particuliÃ¨rement remarquable, par exemple, pour la rÃ©solution de problÃ¨mes mathÃ©matiques, surpassant mÃªme GPT-3 avec un vÃ©rificateur.
-[program aided](https://arxiv.org/abs/2211.10435):
  - ğŸ§  Les grands modÃ¨les de langage (LLM) ont montrÃ© une grande capacitÃ© Ã  effectuer des tÃ¢ches de raisonnement arithmÃ©tique et symbolique en utilisant des exemples limitÃ©s ("few-shot prompting").
  - ğŸ”„ Les mÃ©thodes de prompting telles que "chain-of-thought" sont efficaces pour dÃ©composer les problÃ¨mes en Ã©tapes comprises par les LLMs, mais les LLMs commettent souvent des erreurs logiques et arithmÃ©tiques dans la solution.
  - ğŸ¤– Le modÃ¨le PAL (Program-Aided Language) propose une approche novatrice oÃ¹ le LLM gÃ©nÃ¨re des programmes comme Ã©tapes intermÃ©diaires de raisonnement, mais dÃ©lÃ¨gue la rÃ©solution Ã  un interprÃ¨te Python.
  - ğŸ“Š PAL dÃ©montre une synergie entre un LLM neuronal et un interprÃ¨te symbolique, obtenant des rÃ©sultats plus prÃ©cis que des modÃ¨les plus grands sur 13 tÃ¢ches de raisonnement mathÃ©matique, symbolique et algorithmique.
  - ğŸ“ˆ Par exemple, PAL avec Codex atteint une prÃ©cision few-shot de pointe sur le benchmark GSM8K pour les problÃ¨mes mathÃ©matiques, surpassant PaLM-540B de 15% en top-1.
  - ğŸŒ Le code et les donnÃ©es de PAL sont disponibles publiquement.
- [program of Thougth](https://arxiv.org/abs/2211.12588):
  - ğŸ§  La mÃ©thode CoT est actuellement la mÃ©thode de pointe pour les tÃ¢ches de raisonnement numÃ©rique complexe en utilisant des modÃ¨les de langage.
  - ğŸ’¡ Le 'Program of Thoughts' (PoT) propose de sÃ©parer la computation du raisonnement en utilisant des modÃ¨les de langage pour exprimer le raisonnement sous forme de programme.
  - ğŸ“ˆ PoT prÃ©sente une amÃ©lioration de performance moyenne d'environ 12% par rapport Ã  CoT sur divers ensembles de donnÃ©es, en configuration Ã  faible nombre d'exemples ou sans exemple.
  - ğŸ“Š En combinant PoT avec le dÃ©codage en auto-consistance, des performances de pointe sont obtenues sur tous les ensembles de donnÃ©es de problÃ¨mes mathÃ©matiques et des performances proches de celles de pointe sur les ensembles de donnÃ©es financiÃ¨res.
  - ğŸ’» Les donnÃ©es et le code sont disponibles sur GitHub.
- [planning tasks](https://arxiv.org/abs/2305.16653): 
  - ğŸ¤– Les grands modÃ¨les de langage (LLMs) peuvent agir comme des agents autonomes pour les tÃ¢ches de prise de dÃ©cision sÃ©quentielle.
  - ğŸ“ˆ La plupart des mÃ©thodes existantes ne planifient pas ou utilisent des plans statiques, ce qui limite la performance des agents LLM dans des environnements complexes.
  - ğŸ”„ AdaPlanner propose une approche en boucle fermÃ©e qui permet Ã  l'agent LLM d'affiner son plan en rÃ©ponse aux retours environnementaux.
  - ğŸ“ Il utilise des stratÃ©gies d'affinement Ã  la fois dans le plan et en dehors du plan pour Ã©viter les hallucinations.
  - ğŸ§  Il dÃ©veloppe une structure de prompt en style de code pour faciliter la gÃ©nÃ©ration de plans dans diverses tÃ¢ches et environnements.
  - ğŸ¯ AdaPlanner dÃ©couvre les compÃ©tences en utilisant des plans rÃ©ussis comme exemples Ã  quelques tirs, permettant Ã  l'agent de planifier avec moins de dÃ©monstrations.
  - ğŸš€ Les expÃ©riences montrent qu'AdaPlanner surpasse les mÃ©thodes actuelles avec beaucoup moins d'Ã©chantillons dans diffÃ©rents environnements.
- [Retrieval Augmented generation](https://arxiv.org/abs/2005.11401):
  - ğŸ§  Les grands modÃ¨les de langage prÃ©-entraÃ®nÃ©s stockent des connaissances factuelles dans leurs paramÃ¨tres et obtiennent des rÃ©sultats de pointe lorsqu'ils sont affinÃ©s pour des tÃ¢ches de traitement du langage naturel (NLP) ultÃ©rieures.
  - ğŸŒ Cependant, leur capacitÃ© Ã  accÃ©der et Ã  manipuler prÃ©cisÃ©ment les connaissances est limitÃ©e, ce qui les empÃªche de performer efficacement sur des tÃ¢ches intensives en connaissances.
  - ğŸ” Les modÃ¨les de rÃ©cupÃ©ration augmentÃ©e pour la gÃ©nÃ©ration (RAG) combinent une mÃ©moire paramÃ©trique prÃ©-entraÃ®nÃ©e avec une mÃ©moire non paramÃ©trique, permettant un meilleur accÃ¨s aux connaissances.
  - ğŸ“š Ils utilisent un modÃ¨le sÃ©quentiel prÃ©-entraÃ®nÃ© comme mÃ©moire paramÃ©trique et un index de vecteurs denses de WikipÃ©dia comme mÃ©moire non paramÃ©trique, accessible avec un rÃ©cupÃ©rateur neuronal prÃ©-entraÃ®nÃ©.
  - ğŸ“Š Deux formulations de RAG sont comparÃ©es, l'une conditionnÃ©e sur les mÃªmes passages rÃ©cupÃ©rÃ©s sur toute la sÃ©quence gÃ©nÃ©rÃ©e, l'autre pouvant utiliser diffÃ©rents passages par jeton.
  - ğŸ“ˆ Les modÃ¨les RAG Ã©tablissent de nouvelles rÃ©fÃ©rences sur trois tÃ¢ches de questions-rÃ©ponses en domaine ouvert, surpassant les modÃ¨les sÃ©quentiels paramÃ©triques et les architectures de rÃ©cupÃ©ration et d'extraction spÃ©cifiques Ã  la tÃ¢che.
  - ğŸ—£ï¸ Pour les tÃ¢ches de gÃ©nÃ©ration de langage, les modÃ¨les RAG gÃ©nÃ¨rent un langage plus spÃ©cifique, diversifiÃ© et factuel que les modÃ¨les sÃ©quentiels paramÃ©triques de pointe.
- [IRCoT](https://arxiv.org/abs/2212.10509):
  - ğŸ“š Les modÃ¨les de langage Ã  grande Ã©chelle (LLM) basÃ©s sur des questions sont puissants pour gÃ©nÃ©rer des Ã©tapes de raisonnement en langage naturel ou des chaÃ®nes de pensÃ©e (CoT) pour rÃ©pondre Ã  des questions Ã  plusieurs Ã©tapes.
  - ğŸ§  Cependant, ils rencontrent des difficultÃ©s lorsque les connaissances nÃ©cessaires ne sont pas disponibles pour le LLM ou ne sont pas Ã  jour.
  - ğŸ”„ L'approche "rÃ©cupÃ©rer et lire en une Ã©tape" est insuffisante pour les questions Ã  plusieurs Ã©tapes, car ce qu'il faut rÃ©cupÃ©rer dÃ©pend de ce qui a dÃ©jÃ  Ã©tÃ© dÃ©duit.
  - ğŸš€ Pour rÃ©soudre ce problÃ¨me, ils proposent IRCoT, une nouvelle approche qui entrelace la rÃ©cupÃ©ration avec les Ã©tapes dans une CoT, guidant la rÃ©cupÃ©ration avec la CoT et utilisant les rÃ©sultats rÃ©cupÃ©rÃ©s pour amÃ©liorer la CoT.
  - ğŸ“ˆ En utilisant IRCoT avec GPT3, ils amÃ©liorent considÃ©rablement la rÃ©cupÃ©ration (jusqu'Ã  21 points) ainsi que les questions-rÃ©ponses ultÃ©rieures (jusqu'Ã  15 points) sur quatre ensembles de donnÃ©es diffÃ©rents.
  - ğŸ’¡ IRCoT rÃ©duit l'hallucination du modÃ¨le, ce qui entraÃ®ne un raisonnement CoT factuellement plus prÃ©cis.
- [LeanDojo](https://arxiv.org/abs/2306.15626):
  - ğŸ“š Les grands modÃ¨les de langage (LLMs) montrent une promesse dans la dÃ©monstration de thÃ©orÃ¨mes formels en utilisant des assistants de preuve tels que Lean.
  - ğŸ’¡ Cependant, les mÃ©thodes existantes sont difficiles Ã  reproduire ou Ã  dÃ©velopper en raison de codes privÃ©s, de donnÃ©es et d'exigences de calcul Ã©levÃ©es.
  - ğŸŒ LeanDojo est une aire de jeux Lean open-source qui extrait des donnÃ©es de Lean et permet une interaction avec l'environnement de preuve de maniÃ¨re programmatique.
  - ğŸ§© Il contient des annotations fines des prÃ©misses dans les preuves, fournissant des donnÃ©es prÃ©cieuses pour la sÃ©lection des prÃ©misses, un point critique dans la dÃ©monstration de thÃ©orÃ¨mes.
  - ğŸ¤– Ã€ partir de ces donnÃ©es, ReProver est dÃ©veloppÃ©, un prouveur basÃ© sur LLM augmentÃ© avec une fonction de recherche pour la sÃ©lection de prÃ©misses Ã  partir d'une vaste bibliothÃ¨que mathÃ©matique.
  - â±ï¸ Il est peu coÃ»teux et nÃ©cessite seulement une semaine de formation sur un GPU.
  - ğŸ” Le rÃ©cupÃ©rateur de ReProver utilise la capacitÃ© d'analyse de programme de LeanDojo pour identifier des prÃ©misses accessibles et des exemples nÃ©gatifs difficiles, ce qui rend la recherche beaucoup plus efficace.
  - ğŸ“Š De plus, un nouveau banc d'essai est construit, comprenant 98 734 thÃ©orÃ¨mes et preuves extraites de la bibliothÃ¨que mathÃ©matique de Lean, avec des donnÃ©es exigeantes nÃ©cessitant la gÃ©nÃ©ralisation Ã  des thÃ©orÃ¨mes basÃ©s sur des prÃ©misses inÃ©dites.
  - ğŸ“ˆ Les rÃ©sultats expÃ©rimentaux montrent l'efficacitÃ© de ReProver par rapport aux mÃ©thodes non basÃ©es sur la recherche et Ã  GPT-4.
  - ğŸ”“ Ils fournissent ainsi le premier ensemble de prouveurs de thÃ©orÃ¨mes basÃ©s sur LLM open-source sans donnÃ©es propriÃ©taires et le publient sous une licence MIT permissive pour faciliter les recherches futures.
  - ğŸ† AcceptÃ© Ã  NeurIPS 2023 en tant que prÃ©sentation orale dans la catÃ©gorie "Datasets and Benchmarks Track".
- [DSPy](https://arxiv.org/abs/2310.03714):
  - ğŸ“š La communautÃ© de l'apprentissage automatique explore rapidement les techniques pour stimuler les modÃ¨les de langage et les empiler dans des pipelines rÃ©solvant des tÃ¢ches complexes.
  - ğŸ”„ Les pipelines de modÃ¨les de langage existants utilisent souvent des "modÃ¨les de requÃªte" codÃ©s en dur, ce qui manque de systÃ©maticitÃ©.
  - ğŸ§© DSPy est un modÃ¨le de programmation qui abstrait les pipelines de modÃ¨les de langage en tant que graphes de transformation de texte.
  - ğŸ¤– Les modules DSPy sont paramÃ©trÃ©s et peuvent apprendre Ã  appliquer des compositions de techniques de requÃªtage, d'affinage, d'augmentation et de raisonnement.
  - ğŸš€ Un compilateur DSPy optimise les pipelines DSPy pour maximiser une mÃ©trique donnÃ©e.
  - ğŸ“Š Deux Ã©tudes de cas montrent que de courts programmes DSPy permettent aux modÃ¨les GPT-3.5 et llama2-13b-chat de surpasser les mÃ©thodes traditionnelles de requÃªtage few-shot et les pipelines avec des dÃ©monstrations crÃ©Ã©es par des experts.
  - ğŸ’» DSPy est disponible en ligne pour Ãªtre utilisÃ©.

## POUR ALLER PLUS LOIN

- [00:00](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=0s) ğŸ¤– Cours sur les bases de l'IA pour tous par IBM

  - Cours gratuit de Corsera pour renforcer vos connaissances fondamentales en IA.
  - Aucune expÃ©rience prÃ©alable nÃ©cessaire.
  - Vous apprendrez sur l'IA, les modÃ¨les de langage, la gÃ©nÃ©ration de langage naturel et plus encore.

- [02:05](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=125s) ğŸ§  Cours sur les fondamentaux de Chat GPT

  - Comprenez la fonctionnalitÃ© et les applications de Chat GPT.
  - DÃ©couvrez le rÃ´le d'OpenAI dans le dÃ©veloppement de l'IA.
  - Identifiez les avantages et les limites de Chat GPT.

- [03:31](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=211s) ğŸ Cours Python pour tout le monde sur Coursera

  - Apprenez la programmation en Python pour l'analyse de donnÃ©es et l'IA.
  - DÃ©veloppez des compÃ©tences en programmation et en analyse de donnÃ©es.
  - Obtenez un certificat de Coursera et de l'UniversitÃ© du Michigan.

- [05:08](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=308s) ğŸ¤– Cours sur l'Intelligence Artificielle avec Python par Harvard University

  - Explorez les bases de l'IA moderne.
  - Comprenez les concepts et les algorithmes de l'IA.
  - Utilisez des bibliothÃ¨ques d'apprentissage automatique en Python.

- [06:21](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=381s) ğŸ§  SpÃ©cialisation en Deep Learning par Deep Learning AI

  - AcquÃ©rez une comprÃ©hension approfondie du Deep Learning.
  - Appliquez la thÃ©orie et les applications pratiques en utilisant Python et TensorFlow.
  - Explorez des cas rÃ©els tels que la reconnaissance vocale et les chatbots.

- [07:30](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=450s) ğŸ•¹ï¸ Cours sur l'apprentissage par renforcement profond

  - Apprenez les mÃ©thodes basÃ©es sur la valeur et la politique en apprentissage par renforcement.
  - Comprenez les processus de dÃ©cision de Markov et les Ã©quations de Bellman.
  - Formez des agents pour des tÃ¢ches complexes en utilisant des techniques d'IA.

- [08:14](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=494s) âœï¸ Cours sur l'ingÃ©nierie de prompts pour Chat GPT

  - MaÃ®trisez l'ingÃ©nierie de prompts avancÃ©e pour Chat GPT.
  - Utilisez des modÃ¨les de langage pour crÃ©er des applications sophistiquÃ©es.
  - Recevez un certificat de rÃ©ussite Ã  la fin du cours.

- [08:56](https://www.youtube.com/watch?v=5OneHs9GV0Y&t=536s) ğŸŒŸ Devenir un ingÃ©nieur alimentÃ© par l'IA

  - Apprenez Ã  intÃ©grer Chat GPT, GitHub Copilot et Co-pilot Labs dans votre travail.
  - Utilisez ces outils pour amÃ©liorer votre productivitÃ© en programmation.
  - Explorez les applications de l'IA dans le dÃ©veloppement de logiciels.
 

